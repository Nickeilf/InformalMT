[2019-06-25 11:49:23,564 INFO] Loading checkpoint from models/transformer-fr-en_step_52000.pt
[2019-06-25 11:49:23,836 INFO] Loading vocab from checkpoint at models/transformer-fr-en_step_52000.pt.
[2019-06-25 11:49:23,836 INFO]  * src vocab size = 28666
[2019-06-25 11:49:23,836 INFO]  * tgt vocab size = 28666
[2019-06-25 11:49:23,836 INFO] Building model...
[2019-06-25 11:49:28,751 INFO] NMTModel(
  (encoder): TransformerEncoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(28666, 512, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1)
        )
      )
    )
    (transformer): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
    )
    (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
  )
  (decoder): TransformerDecoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(28666, 512, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1)
        )
      )
    )
    (transformer_layers): ModuleList(
      (0): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
      (1): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
      (2): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
      (3): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
      (4): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
      (5): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
    )
    (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
  )
  (generator): Sequential(
    (0): Linear(in_features=512, out_features=28666, bias=True)
    (1): Cast()
    (2): LogSoftmax()
  )
)
[2019-06-25 11:49:28,753 INFO] encoder: 33592320
[2019-06-25 11:49:28,753 INFO] decoder: 39930874
[2019-06-25 11:49:28,753 INFO] * number of parameters: 73523194
[2019-06-25 11:49:29,497 INFO] Starting training on GPU: [0]
[2019-06-25 11:49:29,497 INFO] Start training loop and validate every 100 steps...
[2019-06-25 11:49:29,497 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 11:49:29,644 INFO] number of examples: 16415
[2019-06-25 11:50:10,810 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 11:50:10,950 INFO] number of examples: 16415
[2019-06-25 11:50:54,378 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 11:50:54,503 INFO] number of examples: 16415
[2019-06-25 11:51:24,676 INFO] Step 52050/300000; acc:  58.53; ppl:  8.16; xent: 2.10; lr: 0.00001; 10268/9829 tok/s;    115 sec
[2019-06-25 11:51:35,962 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 11:51:36,116 INFO] number of examples: 16415
[2019-06-25 11:52:20,026 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 11:52:20,156 INFO] number of examples: 16415
[2019-06-25 11:53:03,743 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 11:53:03,927 INFO] number of examples: 16415
[2019-06-25 11:53:20,509 INFO] Step 52100/300000; acc:  61.00; ppl:  6.93; xent: 1.94; lr: 0.00001; 10142/9726 tok/s;    231 sec
[2019-06-25 11:53:20,511 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.valid.0.pt
[2019-06-25 11:53:20,519 INFO] number of examples: 886
[2019-06-25 11:53:25,920 INFO] Validation perplexity: 49.4831
[2019-06-25 11:53:25,921 INFO] Validation accuracy: 39.69
[2019-06-25 11:53:25,921 INFO] Model is improving ppl: inf --> 49.4831.
[2019-06-25 11:53:25,921 INFO] Model is improving acc: -inf --> 39.69.
[2019-06-25 11:53:25,979 INFO] Saving checkpoint models/transformer-fr-en.tune_step_52100.pt
[2019-06-25 11:53:51,879 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 11:53:52,018 INFO] number of examples: 16415
[2019-06-25 11:54:36,073 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 11:54:36,201 INFO] number of examples: 16415
[2019-06-25 11:55:20,049 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 11:55:20,193 INFO] number of examples: 16415
[2019-06-25 11:55:22,761 INFO] Step 52150/300000; acc:  62.20; ppl:  6.47; xent: 1.87; lr: 0.00001; 9526/9135 tok/s;    353 sec
[2019-06-25 11:56:01,622 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 11:56:01,756 INFO] number of examples: 16415
[2019-06-25 11:56:45,627 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 11:56:45,847 INFO] number of examples: 16415
[2019-06-25 11:57:18,804 INFO] Step 52200/300000; acc:  63.12; ppl:  6.10; xent: 1.81; lr: 0.00001; 10134/9710 tok/s;    469 sec
[2019-06-25 11:57:18,805 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.valid.0.pt
[2019-06-25 11:57:18,812 INFO] number of examples: 886
[2019-06-25 11:57:24,229 INFO] Validation perplexity: 47.254
[2019-06-25 11:57:24,229 INFO] Validation accuracy: 40.2984
[2019-06-25 11:57:24,229 INFO] Model is improving ppl: 49.4831 --> 47.254.
[2019-06-25 11:57:24,229 INFO] Model is improving acc: 39.69 --> 40.2984.
[2019-06-25 11:57:24,291 INFO] Saving checkpoint models/transformer-fr-en.tune_step_52200.pt
[2019-06-25 11:57:34,247 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 11:57:34,382 INFO] number of examples: 16415
[2019-06-25 11:58:18,318 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 11:58:18,511 INFO] number of examples: 16415
[2019-06-25 11:59:02,263 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 11:59:02,401 INFO] number of examples: 16415
[2019-06-25 11:59:21,203 INFO] Step 52250/300000; acc:  63.72; ppl:  5.88; xent: 1.77; lr: 0.00001; 9649/9241 tok/s;    592 sec
[2019-06-25 11:59:43,907 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 11:59:44,037 INFO] number of examples: 16415
[2019-06-25 12:00:27,853 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 12:00:28,007 INFO] number of examples: 16415
[2019-06-25 12:01:11,864 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 12:01:11,998 INFO] number of examples: 16415
[2019-06-25 12:01:16,753 INFO] Step 52300/300000; acc:  64.21; ppl:  5.72; xent: 1.74; lr: 0.00001; 10040/9639 tok/s;    707 sec
[2019-06-25 12:01:16,755 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.valid.0.pt
[2019-06-25 12:01:16,763 INFO] number of examples: 886
[2019-06-25 12:01:21,944 INFO] Validation perplexity: 46.4184
[2019-06-25 12:01:21,944 INFO] Validation accuracy: 40.6714
[2019-06-25 12:01:21,944 INFO] Model is improving ppl: 47.254 --> 46.4184.
[2019-06-25 12:01:21,944 INFO] Model is improving acc: 40.2984 --> 40.6714.
[2019-06-25 12:01:22,002 INFO] Saving checkpoint models/transformer-fr-en.tune_step_52300.pt
[2019-06-25 12:01:59,354 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 12:01:59,541 INFO] number of examples: 16415
[2019-06-25 12:02:43,331 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 12:02:43,466 INFO] number of examples: 16415
[2019-06-25 12:03:18,257 INFO] Step 52350/300000; acc:  64.75; ppl:  5.52; xent: 1.71; lr: 0.00001; 9662/9254 tok/s;    829 sec
[2019-06-25 12:03:25,058 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 12:03:25,188 INFO] number of examples: 16415
[2019-06-25 12:04:09,033 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 12:04:09,174 INFO] number of examples: 16415
[2019-06-25 12:04:52,925 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 12:04:53,057 INFO] number of examples: 16415
[2019-06-25 12:05:14,282 INFO] Step 52400/300000; acc:  65.17; ppl:  5.37; xent: 1.68; lr: 0.00001; 10222/9786 tok/s;    945 sec
[2019-06-25 12:05:14,283 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.valid.0.pt
[2019-06-25 12:05:14,344 INFO] number of examples: 886
[2019-06-25 12:05:19,526 INFO] Validation perplexity: 45.8318
[2019-06-25 12:05:19,526 INFO] Validation accuracy: 41.0005
[2019-06-25 12:05:19,527 INFO] Model is improving ppl: 46.4184 --> 45.8318.
[2019-06-25 12:05:19,527 INFO] Model is improving acc: 40.6714 --> 41.0005.
[2019-06-25 12:05:19,586 INFO] Saving checkpoint models/transformer-fr-en.tune_step_52400.pt
[2019-06-25 12:05:40,509 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 12:05:40,648 INFO] number of examples: 16415
[2019-06-25 12:06:24,443 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 12:06:24,582 INFO] number of examples: 16415
[2019-06-25 12:07:08,454 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 12:07:08,644 INFO] number of examples: 16415
[2019-06-25 12:07:15,880 INFO] Step 52450/300000; acc:  65.53; ppl:  5.27; xent: 1.66; lr: 0.00001; 9575/9190 tok/s;   1066 sec
[2019-06-25 12:07:50,132 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 12:07:50,270 INFO] number of examples: 16415
[2019-06-25 12:08:34,089 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 12:08:34,226 INFO] number of examples: 16415
[2019-06-25 12:09:11,272 INFO] Step 52500/300000; acc:  65.86; ppl:  5.15; xent: 1.64; lr: 0.00001; 10107/9692 tok/s;   1182 sec
[2019-06-25 12:09:11,273 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.valid.0.pt
[2019-06-25 12:09:11,281 INFO] number of examples: 886
[2019-06-25 12:09:16,498 INFO] Validation perplexity: 45.7636
[2019-06-25 12:09:16,498 INFO] Validation accuracy: 41.1979
[2019-06-25 12:09:16,498 INFO] Model is improving ppl: 45.8318 --> 45.7636.
[2019-06-25 12:09:16,498 INFO] Model is improving acc: 41.0005 --> 41.1979.
[2019-06-25 12:09:16,557 INFO] Saving checkpoint models/transformer-fr-en.tune_step_52500.pt
[2019-06-25 12:09:21,811 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 12:09:21,953 INFO] number of examples: 16415
[2019-06-25 12:10:05,762 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 12:10:05,896 INFO] number of examples: 16415
[2019-06-25 12:10:49,775 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 12:10:49,923 INFO] number of examples: 16415
[2019-06-25 12:11:13,393 INFO] Step 52550/300000; acc:  66.25; ppl:  5.04; xent: 1.62; lr: 0.00001; 9711/9290 tok/s;   1304 sec
[2019-06-25 12:11:31,466 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 12:11:31,603 INFO] number of examples: 16415
[2019-06-25 12:12:15,388 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 12:12:15,581 INFO] number of examples: 16415
[2019-06-25 12:12:59,455 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 12:12:59,594 INFO] number of examples: 16415
[2019-06-25 12:13:09,061 INFO] Step 52600/300000; acc:  66.48; ppl:  4.96; xent: 1.60; lr: 0.00001; 10085/9683 tok/s;   1420 sec
[2019-06-25 12:13:09,062 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.valid.0.pt
[2019-06-25 12:13:09,070 INFO] number of examples: 886
[2019-06-25 12:13:14,283 INFO] Validation perplexity: 45.8815
[2019-06-25 12:13:14,284 INFO] Validation accuracy: 41.3735
[2019-06-25 12:13:14,284 INFO] Stalled patience: 4/5
[2019-06-25 12:13:14,342 INFO] Saving checkpoint models/transformer-fr-en.tune_step_52600.pt
[2019-06-25 12:13:47,058 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 12:13:47,190 INFO] number of examples: 16415
[2019-06-25 12:14:31,074 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 12:14:31,220 INFO] number of examples: 16415
[2019-06-25 12:15:10,570 INFO] Step 52650/300000; acc:  66.78; ppl:  4.87; xent: 1.58; lr: 0.00001; 9616/9203 tok/s;   1541 sec
[2019-06-25 12:15:12,816 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 12:15:12,948 INFO] number of examples: 16415
[2019-06-25 12:15:56,749 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 12:15:56,938 INFO] number of examples: 16415
[2019-06-25 12:16:40,771 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 12:16:40,909 INFO] number of examples: 16415
[2019-06-25 12:17:06,607 INFO] Step 52700/300000; acc:  67.13; ppl:  4.76; xent: 1.56; lr: 0.00001; 10193/9767 tok/s;   1657 sec
[2019-06-25 12:17:06,608 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.valid.0.pt
[2019-06-25 12:17:06,617 INFO] number of examples: 886
[2019-06-25 12:17:11,824 INFO] Validation perplexity: 45.7112
[2019-06-25 12:17:11,824 INFO] Validation accuracy: 41.5669
[2019-06-25 12:17:11,825 INFO] Model is improving ppl: 45.7636 --> 45.7112.
[2019-06-25 12:17:11,825 INFO] Model is improving acc: 41.1979 --> 41.5669.
[2019-06-25 12:17:11,882 INFO] Saving checkpoint models/transformer-fr-en.tune_step_52700.pt
[2019-06-25 12:17:28,360 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 12:17:28,551 INFO] number of examples: 16415
[2019-06-25 12:18:12,338 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 12:18:12,475 INFO] number of examples: 16415
[2019-06-25 12:18:56,375 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 12:18:56,507 INFO] number of examples: 16415
[2019-06-25 12:19:08,407 INFO] Step 52750/300000; acc:  67.29; ppl:  4.71; xent: 1.55; lr: 0.00001; 9584/9194 tok/s;   1779 sec
[2019-06-25 12:19:38,130 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 12:19:38,276 INFO] number of examples: 16415
[2019-06-25 12:20:22,090 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 12:20:22,228 INFO] number of examples: 16415
[2019-06-25 12:21:03,834 INFO] Step 52800/300000; acc:  67.58; ppl:  4.63; xent: 1.53; lr: 0.00001; 10080/9659 tok/s;   1894 sec
[2019-06-25 12:21:03,835 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.valid.0.pt
[2019-06-25 12:21:03,844 INFO] number of examples: 886
[2019-06-25 12:21:09,070 INFO] Validation perplexity: 46.1446
[2019-06-25 12:21:09,070 INFO] Validation accuracy: 41.6607
[2019-06-25 12:21:09,070 INFO] Stalled patience: 4/5
[2019-06-25 12:21:09,130 INFO] Saving checkpoint models/transformer-fr-en.tune_step_52800.pt
[2019-06-25 12:21:09,844 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 12:21:10,001 INFO] number of examples: 16415
[2019-06-25 12:21:53,773 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 12:21:53,918 INFO] number of examples: 16415
[2019-06-25 12:22:37,790 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 12:22:37,985 INFO] number of examples: 16415
[2019-06-25 12:23:05,987 INFO] Step 52850/300000; acc:  67.89; ppl:  4.55; xent: 1.51; lr: 0.00001; 9678/9261 tok/s;   2016 sec
[2019-06-25 12:23:19,564 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 12:23:19,702 INFO] number of examples: 16415
[2019-06-25 12:24:03,482 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 12:24:03,614 INFO] number of examples: 16415
[2019-06-25 12:24:47,608 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 12:24:47,756 INFO] number of examples: 16415
[2019-06-25 12:25:01,879 INFO] Step 52900/300000; acc:  68.07; ppl:  4.49; xent: 1.50; lr: 0.00001; 10136/9731 tok/s;   2132 sec
[2019-06-25 12:25:01,880 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.valid.0.pt
[2019-06-25 12:25:01,888 INFO] number of examples: 886
[2019-06-25 12:25:07,102 INFO] Validation perplexity: 45.8405
[2019-06-25 12:25:07,102 INFO] Validation accuracy: 41.8422
[2019-06-25 12:25:07,102 INFO] Stalled patience: 3/5
[2019-06-25 12:25:07,160 INFO] Saving checkpoint models/transformer-fr-en.tune_step_52900.pt
[2019-06-25 12:25:35,196 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 12:25:35,333 INFO] number of examples: 16415
[2019-06-25 12:26:19,128 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 12:26:19,321 INFO] number of examples: 16415
[2019-06-25 12:27:00,917 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 12:27:01,055 INFO] number of examples: 16415
[2019-06-25 12:27:03,452 INFO] Step 52950/300000; acc:  68.29; ppl:  4.45; xent: 1.49; lr: 0.00001; 9557/9162 tok/s;   2254 sec
[2019-06-25 12:27:44,865 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 12:27:44,995 INFO] number of examples: 16415
[2019-06-25 12:28:29,105 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 12:28:29,266 INFO] number of examples: 16415
[2019-06-25 12:29:20,432 INFO] Loading checkpoint from models/transformer-fr-en_step_52000.pt
[2019-06-25 12:29:20,700 INFO] Loading vocab from checkpoint at models/transformer-fr-en_step_52000.pt.
[2019-06-25 12:29:20,700 INFO]  * src vocab size = 28666
[2019-06-25 12:29:20,700 INFO]  * tgt vocab size = 28666
[2019-06-25 12:29:20,701 INFO] Building model...
[2019-06-25 12:29:23,586 INFO] NMTModel(
  (encoder): TransformerEncoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(28666, 512, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1)
        )
      )
    )
    (transformer): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
    )
    (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
  )
  (decoder): TransformerDecoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(28666, 512, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1)
        )
      )
    )
    (transformer_layers): ModuleList(
      (0): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
      (1): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
      (2): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
      (3): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
      (4): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
      (5): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
    )
    (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
  )
  (generator): Sequential(
    (0): Linear(in_features=512, out_features=28666, bias=True)
    (1): Cast()
    (2): LogSoftmax()
  )
)
[2019-06-25 12:29:23,589 INFO] encoder: 33592320
[2019-06-25 12:29:23,589 INFO] decoder: 39930874
[2019-06-25 12:29:23,589 INFO] * number of parameters: 73523194
[2019-06-25 12:29:24,019 INFO] Starting training on GPU: [0]
[2019-06-25 12:29:24,019 INFO] Start training loop and validate every 200 steps...
[2019-06-25 12:29:24,020 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 12:29:24,157 INFO] number of examples: 16415
[2019-06-25 12:30:05,385 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 12:30:05,526 INFO] number of examples: 16415
[2019-06-25 12:30:49,159 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 12:30:49,284 INFO] number of examples: 16415
[2019-06-25 12:31:19,630 INFO] Step 52050/300000; acc:  58.53; ppl:  8.16; xent: 2.10; lr: 0.00001; 10230/9793 tok/s;    116 sec
[2019-06-25 12:31:30,920 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 12:31:31,074 INFO] number of examples: 16415
[2019-06-25 12:32:14,849 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 12:32:14,978 INFO] number of examples: 16415
[2019-06-25 12:32:58,772 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 12:32:58,957 INFO] number of examples: 16415
[2019-06-25 12:33:15,503 INFO] Step 52100/300000; acc:  61.00; ppl:  6.93; xent: 1.94; lr: 0.00001; 10139/9723 tok/s;    231 sec
[2019-06-25 12:33:40,504 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 12:33:40,641 INFO] number of examples: 16415
[2019-06-25 12:34:24,498 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 12:34:24,630 INFO] number of examples: 16415
[2019-06-25 12:35:10,503 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 12:35:10,653 INFO] number of examples: 16415
[2019-06-25 12:35:13,398 INFO] Step 52150/300000; acc:  62.20; ppl:  6.47; xent: 1.87; lr: 0.00001; 9878/9473 tok/s;    349 sec
[2019-06-25 12:35:53,141 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 12:35:53,272 INFO] number of examples: 16415
[2019-06-25 12:36:37,063 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 12:36:37,256 INFO] number of examples: 16415
[2019-06-25 12:37:09,712 INFO] Step 52200/300000; acc:  63.12; ppl:  6.10; xent: 1.81; lr: 0.00001; 10111/9687 tok/s;    466 sec
[2019-06-25 12:37:09,713 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.valid.0.pt
[2019-06-25 12:37:09,721 INFO] number of examples: 886
[2019-06-25 12:37:15,133 INFO] Validation perplexity: 47.254
[2019-06-25 12:37:15,133 INFO] Validation accuracy: 40.2984
[2019-06-25 12:37:15,134 INFO] Model is improving ppl: inf --> 47.254.
[2019-06-25 12:37:15,134 INFO] Model is improving acc: -inf --> 40.2984.
[2019-06-25 12:37:15,192 INFO] Saving checkpoint models/transformer-fr-en.tune_step_52200.pt
[2019-06-25 12:37:29,230 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 12:37:29,369 INFO] number of examples: 16415
[2019-06-25 12:38:13,097 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 12:38:13,227 INFO] number of examples: 16415
[2019-06-25 12:38:57,083 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 12:38:57,222 INFO] number of examples: 16415
[2019-06-25 12:39:16,042 INFO] Step 52250/300000; acc:  63.72; ppl:  5.88; xent: 1.77; lr: 0.00001; 9349/8953 tok/s;    592 sec
[2019-06-25 12:39:38,754 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 12:39:38,882 INFO] number of examples: 16415
[2019-06-25 12:40:22,657 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 12:40:22,838 INFO] number of examples: 16415
[2019-06-25 12:41:06,722 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 12:41:06,857 INFO] number of examples: 16415
[2019-06-25 12:41:11,614 INFO] Step 52300/300000; acc:  64.21; ppl:  5.72; xent: 1.74; lr: 0.00001; 10038/9638 tok/s;    708 sec
[2019-06-25 12:41:48,403 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 12:41:48,597 INFO] number of examples: 16415
[2019-06-25 12:42:32,576 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 12:42:32,713 INFO] number of examples: 16415
[2019-06-25 12:43:08,690 INFO] Step 52350/300000; acc:  64.75; ppl:  5.52; xent: 1.71; lr: 0.00001; 10028/9604 tok/s;    825 sec
[2019-06-25 12:43:15,905 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 12:43:16,072 INFO] number of examples: 16415
[2019-06-25 12:44:01,416 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 12:44:01,601 INFO] number of examples: 16415
[2019-06-25 12:44:47,194 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 12:44:47,340 INFO] number of examples: 16415
[2019-06-25 12:45:09,169 INFO] Step 52400/300000; acc:  65.17; ppl:  5.37; xent: 1.68; lr: 0.00001; 9844/9424 tok/s;    945 sec
[2019-06-25 12:45:09,170 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.valid.0.pt
[2019-06-25 12:45:09,178 INFO] number of examples: 886
[2019-06-25 12:45:14,741 INFO] Validation perplexity: 45.8318
[2019-06-25 12:45:14,741 INFO] Validation accuracy: 41.0005
[2019-06-25 12:45:14,741 INFO] Model is improving ppl: 47.254 --> 45.8318.
[2019-06-25 12:45:14,742 INFO] Model is improving acc: 40.2984 --> 41.0005.
[2019-06-25 12:45:14,805 INFO] Saving checkpoint models/transformer-fr-en.tune_step_52400.pt
[2019-06-25 12:45:40,992 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 12:45:41,180 INFO] number of examples: 16415
[2019-06-25 12:46:25,350 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 12:46:25,496 INFO] number of examples: 16415
[2019-06-25 12:47:09,429 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 12:47:09,556 INFO] number of examples: 16415
[2019-06-25 12:47:16,853 INFO] Step 52450/300000; acc:  65.53; ppl:  5.27; xent: 1.66; lr: 0.00001; 9119/8752 tok/s;   1073 sec
[2019-06-25 12:47:51,151 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 12:47:51,293 INFO] number of examples: 16415
[2019-06-25 12:48:35,080 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 12:48:35,212 INFO] number of examples: 16415
[2019-06-25 12:49:12,177 INFO] Step 52500/300000; acc:  65.86; ppl:  5.15; xent: 1.64; lr: 0.00001; 10113/9698 tok/s;   1188 sec
[2019-06-25 12:49:16,790 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 12:49:16,975 INFO] number of examples: 16415
[2019-06-25 12:50:00,794 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 12:50:00,929 INFO] number of examples: 16415
[2019-06-25 12:50:44,784 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 12:50:44,912 INFO] number of examples: 16415
[2019-06-25 12:51:08,457 INFO] Step 52550/300000; acc:  66.25; ppl:  5.04; xent: 1.62; lr: 0.00001; 10199/9756 tok/s;   1304 sec
[2019-06-25 12:51:26,532 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 12:51:26,673 INFO] number of examples: 16415
[2019-06-25 12:52:10,492 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 12:52:10,624 INFO] number of examples: 16415
[2019-06-25 12:52:54,555 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 12:52:54,750 INFO] number of examples: 16415
[2019-06-25 12:53:04,216 INFO] Step 52600/300000; acc:  66.48; ppl:  4.96; xent: 1.60; lr: 0.00001; 10077/9676 tok/s;   1420 sec
[2019-06-25 12:53:04,217 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.valid.0.pt
[2019-06-25 12:53:04,226 INFO] number of examples: 886
[2019-06-25 12:53:09,454 INFO] Validation perplexity: 45.8815
[2019-06-25 12:53:09,454 INFO] Validation accuracy: 41.3735
[2019-06-25 12:53:09,455 INFO] Stalled patience: 7/8
[2019-06-25 12:53:09,512 INFO] Saving checkpoint models/transformer-fr-en.tune_step_52600.pt
[2019-06-25 12:53:47,817 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 12:53:47,953 INFO] number of examples: 16415
[2019-06-25 12:54:31,774 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 12:54:31,964 INFO] number of examples: 16415
[2019-06-25 12:55:11,336 INFO] Step 52650/300000; acc:  66.78; ppl:  4.87; xent: 1.58; lr: 0.00001; 9191/8797 tok/s;   1547 sec
[2019-06-25 12:55:13,587 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 12:55:13,726 INFO] number of examples: 16415
[2019-06-25 12:55:57,583 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 12:55:57,714 INFO] number of examples: 16415
[2019-06-25 12:56:41,646 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 12:56:41,791 INFO] number of examples: 16415
[2019-06-25 12:57:07,521 INFO] Step 52700/300000; acc:  67.13; ppl:  4.76; xent: 1.56; lr: 0.00001; 10180/9755 tok/s;   1664 sec
[2019-06-25 12:57:23,385 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 12:57:23,521 INFO] number of examples: 16415
[2019-06-25 12:58:07,366 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 12:58:07,558 INFO] number of examples: 16415
[2019-06-25 12:58:51,499 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 12:58:51,636 INFO] number of examples: 16415
[2019-06-25 12:59:03,483 INFO] Step 52750/300000; acc:  67.29; ppl:  4.71; xent: 1.55; lr: 0.00001; 10066/9657 tok/s;   1779 sec
[2019-06-25 12:59:33,204 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 12:59:33,338 INFO] number of examples: 16415
[2019-06-25 13:00:17,219 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 13:00:17,365 INFO] number of examples: 16415
[2019-06-25 13:00:58,949 INFO] Step 52800/300000; acc:  67.58; ppl:  4.63; xent: 1.53; lr: 0.00001; 10076/9656 tok/s;   1895 sec
[2019-06-25 13:00:58,950 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.valid.0.pt
[2019-06-25 13:00:58,959 INFO] number of examples: 886
[2019-06-25 13:01:04,180 INFO] Validation perplexity: 46.1446
[2019-06-25 13:01:04,180 INFO] Validation accuracy: 41.6607
[2019-06-25 13:01:04,180 INFO] Stalled patience: 6/8
[2019-06-25 13:01:04,239 INFO] Saving checkpoint models/transformer-fr-en.tune_step_52800.pt
[2019-06-25 13:01:09,015 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 13:01:09,149 INFO] number of examples: 16415
[2019-06-25 13:01:52,944 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 13:01:53,091 INFO] number of examples: 16415
[2019-06-25 13:02:36,955 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 13:02:37,097 INFO] number of examples: 16415
[2019-06-25 13:03:05,127 INFO] Step 52850/300000; acc:  67.89; ppl:  4.55; xent: 1.51; lr: 0.00001; 9369/8965 tok/s;   2021 sec
[2019-06-25 13:03:18,714 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 13:03:18,907 INFO] number of examples: 16415
[2019-06-25 13:04:02,761 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 13:04:02,900 INFO] number of examples: 16415
[2019-06-25 13:04:46,833 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 13:04:46,969 INFO] number of examples: 16415
[2019-06-25 13:05:01,169 INFO] Step 52900/300000; acc:  68.07; ppl:  4.49; xent: 1.50; lr: 0.00001; 10123/9718 tok/s;   2137 sec
[2019-06-25 13:05:28,575 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 13:05:28,722 INFO] number of examples: 16415
[2019-06-25 13:06:12,537 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 13:06:12,674 INFO] number of examples: 16415
[2019-06-25 13:06:54,301 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 13:06:54,496 INFO] number of examples: 16415
[2019-06-25 13:06:56,893 INFO] Step 52950/300000; acc:  68.29; ppl:  4.45; xent: 1.49; lr: 0.00001; 10041/9625 tok/s;   2253 sec
[2019-06-25 13:07:38,326 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 13:07:38,466 INFO] number of examples: 16415
[2019-06-25 13:08:22,313 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 13:08:22,446 INFO] number of examples: 16415
[2019-06-25 13:08:52,829 INFO] Step 53000/300000; acc:  68.57; ppl:  4.36; xent: 1.47; lr: 0.00001; 10202/9763 tok/s;   2369 sec
[2019-06-25 13:08:52,830 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.valid.0.pt
[2019-06-25 13:08:52,839 INFO] number of examples: 886
[2019-06-25 13:08:58,107 INFO] Validation perplexity: 46.2056
[2019-06-25 13:08:58,107 INFO] Validation accuracy: 41.9539
[2019-06-25 13:08:58,108 INFO] Stalled patience: 5/8
[2019-06-25 13:08:58,167 INFO] Saving checkpoint models/transformer-fr-en.tune_step_53000.pt
[2019-06-25 13:09:10,072 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 13:09:10,217 INFO] number of examples: 16415
[2019-06-25 13:09:54,042 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 13:09:54,178 INFO] number of examples: 16415
[2019-06-25 13:10:38,220 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 13:10:38,378 INFO] number of examples: 16415
[2019-06-25 13:10:54,883 INFO] Step 53050/300000; acc:  68.73; ppl:  4.32; xent: 1.46; lr: 0.00001; 9624/9230 tok/s;   2491 sec
[2019-06-25 13:11:19,940 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 13:11:20,078 INFO] number of examples: 16415
[2019-06-25 13:12:03,917 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 13:12:04,113 INFO] number of examples: 16415
[2019-06-25 13:12:45,719 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 13:12:45,860 INFO] number of examples: 16415
[2019-06-25 13:12:50,735 INFO] Step 53100/300000; acc:  68.88; ppl:  4.27; xent: 1.45; lr: 0.00001; 10053/9640 tok/s;   2607 sec
[2019-06-25 13:13:29,698 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 13:13:29,842 INFO] number of examples: 16415
[2019-06-25 13:14:13,783 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 13:14:13,938 INFO] number of examples: 16415
[2019-06-25 13:14:46,462 INFO] Step 53150/300000; acc:  69.20; ppl:  4.20; xent: 1.43; lr: 0.00001; 10138/9715 tok/s;   2722 sec
[2019-06-25 13:14:55,576 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 13:14:55,714 INFO] number of examples: 16415
[2019-06-25 13:15:39,464 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 13:15:39,659 INFO] number of examples: 16415
[2019-06-25 13:16:23,554 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 13:16:23,694 INFO] number of examples: 16415
[2019-06-25 13:16:42,524 INFO] Step 53200/300000; acc:  69.36; ppl:  4.15; xent: 1.42; lr: 0.00001; 10200/9768 tok/s;   2839 sec
[2019-06-25 13:16:42,525 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.valid.0.pt
[2019-06-25 13:16:42,533 INFO] number of examples: 886
[2019-06-25 13:16:47,723 INFO] Validation perplexity: 46.0182
[2019-06-25 13:16:47,723 INFO] Validation accuracy: 42.2072
[2019-06-25 13:16:47,724 INFO] Stalled patience: 4/8
[2019-06-25 13:16:47,782 INFO] Saving checkpoint models/transformer-fr-en.tune_step_53200.pt
[2019-06-25 13:17:11,130 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 13:17:11,262 INFO] number of examples: 16415
[2019-06-25 13:17:55,157 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 13:17:55,304 INFO] number of examples: 16415
[2019-06-25 13:18:36,944 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 13:18:37,084 INFO] number of examples: 16415
[2019-06-25 13:18:44,202 INFO] Step 53250/300000; acc:  69.49; ppl:  4.13; xent: 1.42; lr: 0.00001; 9532/9152 tok/s;   2960 sec
[2019-06-25 13:19:20,913 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 13:19:21,102 INFO] number of examples: 16415
[2019-06-25 13:20:04,937 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 13:20:05,075 INFO] number of examples: 16415
[2019-06-25 13:20:39,868 INFO] Step 53300/300000; acc:  69.72; ppl:  4.07; xent: 1.40; lr: 0.00001; 10144/9715 tok/s;   3076 sec
[2019-06-25 13:20:46,651 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 13:20:46,848 INFO] number of examples: 16415
[2019-06-25 13:21:30,682 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 13:21:30,824 INFO] number of examples: 16415
[2019-06-25 13:22:14,764 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 13:22:14,898 INFO] number of examples: 16415
[2019-06-25 13:22:36,143 INFO] Step 53350/300000; acc:  69.98; ppl:  4.01; xent: 1.39; lr: 0.00001; 10208/9774 tok/s;   3192 sec
[2019-06-25 13:22:56,451 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 13:22:56,640 INFO] number of examples: 16415
[2019-06-25 13:23:40,498 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 13:23:40,643 INFO] number of examples: 16415
[2019-06-25 13:24:22,282 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 13:24:22,485 INFO] number of examples: 16415
[2019-06-25 13:24:32,021 INFO] Step 53400/300000; acc:  70.10; ppl:  3.98; xent: 1.38; lr: 0.00001; 10032/9625 tok/s;   3308 sec
[2019-06-25 13:24:32,022 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.valid.0.pt
[2019-06-25 13:24:32,030 INFO] number of examples: 886
[2019-06-25 13:24:37,245 INFO] Validation perplexity: 47.0445
[2019-06-25 13:24:37,245 INFO] Validation accuracy: 42.2371
[2019-06-25 13:24:37,246 INFO] Stalled patience: 3/8
[2019-06-25 13:24:37,305 INFO] Saving checkpoint models/transformer-fr-en.tune_step_53400.pt
[2019-06-25 13:25:12,205 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 13:25:12,350 INFO] number of examples: 16415
[2019-06-25 13:25:56,217 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 13:25:56,352 INFO] number of examples: 16415
[2019-06-25 13:26:33,486 INFO] Step 53450/300000; acc:  70.28; ppl:  3.94; xent: 1.37; lr: 0.00001; 9619/9224 tok/s;   3429 sec
[2019-06-25 13:26:38,046 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 13:26:38,198 INFO] number of examples: 16415
[2019-06-25 13:27:22,020 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 13:27:22,159 INFO] number of examples: 16415
[2019-06-25 13:28:06,075 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 13:28:06,270 INFO] number of examples: 16415
[2019-06-25 13:28:29,685 INFO] Step 53500/300000; acc:  70.58; ppl:  3.89; xent: 1.36; lr: 0.00001; 10174/9737 tok/s;   3546 sec
[2019-06-25 13:28:47,841 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 13:28:47,981 INFO] number of examples: 16415
[2019-06-25 13:29:31,762 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 13:29:31,895 INFO] number of examples: 16415
[2019-06-25 13:30:13,510 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 13:30:13,657 INFO] number of examples: 16415
[2019-06-25 13:30:25,432 INFO] Step 53550/300000; acc:  70.67; ppl:  3.86; xent: 1.35; lr: 0.00001; 10109/9700 tok/s;   3661 sec
[2019-06-25 13:30:57,471 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 13:30:57,608 INFO] number of examples: 16415
[2019-06-25 13:31:41,413 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 13:31:41,607 INFO] number of examples: 16415
[2019-06-25 13:32:20,869 INFO] Step 53600/300000; acc:  70.86; ppl:  3.83; xent: 1.34; lr: 0.00001; 10095/9669 tok/s;   3777 sec
[2019-06-25 13:32:20,870 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.valid.0.pt
[2019-06-25 13:32:20,878 INFO] number of examples: 886
[2019-06-25 13:32:26,108 INFO] Validation perplexity: 47.0605
[2019-06-25 13:32:26,108 INFO] Validation accuracy: 42.4984
[2019-06-25 13:32:26,108 INFO] Stalled patience: 2/8
[2019-06-25 13:32:26,166 INFO] Saving checkpoint models/transformer-fr-en.tune_step_53600.pt
[2019-06-25 13:32:29,071 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 13:32:29,213 INFO] number of examples: 16415
[2019-06-25 13:33:13,016 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 13:33:13,149 INFO] number of examples: 16415
[2019-06-25 13:33:57,153 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 13:33:57,301 INFO] number of examples: 16415
[2019-06-25 13:34:22,940 INFO] Step 53650/300000; acc:  71.13; ppl:  3.76; xent: 1.32; lr: 0.00001; 9714/9303 tok/s;   3899 sec
[2019-06-25 13:34:38,795 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 13:34:38,933 INFO] number of examples: 16415
[2019-06-25 13:35:22,708 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 13:35:22,903 INFO] number of examples: 16415
[2019-06-25 13:36:04,534 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 13:36:04,675 INFO] number of examples: 16415
[2019-06-25 13:36:18,786 INFO] Step 53700/300000; acc:  71.13; ppl:  3.76; xent: 1.32; lr: 0.00001; 10060/9655 tok/s;   4015 sec
[2019-06-25 13:36:48,588 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 13:36:48,721 INFO] number of examples: 16415
[2019-06-25 13:37:32,674 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 13:37:32,821 INFO] number of examples: 16415
[2019-06-25 13:38:14,423 INFO] Step 53750/300000; acc:  71.38; ppl:  3.71; xent: 1.31; lr: 0.00001; 10077/9651 tok/s;   4130 sec
[2019-06-25 13:38:14,438 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 13:38:14,577 INFO] number of examples: 16415
[2019-06-25 13:38:58,435 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 13:38:58,632 INFO] number of examples: 16415
[2019-06-25 13:39:42,585 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 13:39:42,726 INFO] number of examples: 16415
[2019-06-25 13:40:10,640 INFO] Step 53800/300000; acc:  71.57; ppl:  3.67; xent: 1.30; lr: 0.00001; 10142/9710 tok/s;   4247 sec
[2019-06-25 13:40:10,642 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.valid.0.pt
[2019-06-25 13:40:10,650 INFO] number of examples: 886
[2019-06-25 13:40:15,847 INFO] Validation perplexity: 47.3125
[2019-06-25 13:40:15,847 INFO] Validation accuracy: 42.64
[2019-06-25 13:40:15,847 INFO] Stalled patience: 1/8
[2019-06-25 13:40:15,906 INFO] Saving checkpoint models/transformer-fr-en.tune_step_53800.pt
[2019-06-25 13:40:30,194 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 13:40:30,392 INFO] number of examples: 16415
[2019-06-25 13:41:14,236 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 13:41:14,379 INFO] number of examples: 16415
[2019-06-25 13:41:56,020 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 13:41:56,153 INFO] number of examples: 16415
[2019-06-25 13:42:12,703 INFO] Step 53850/300000; acc:  71.71; ppl:  3.64; xent: 1.29; lr: 0.00001; 9650/9260 tok/s;   4369 sec
[2019-06-25 13:42:40,103 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 13:42:40,252 INFO] number of examples: 16415
[2019-06-25 13:43:24,091 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 13:43:24,231 INFO] number of examples: 16415
[2019-06-25 13:44:05,801 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 13:44:05,996 INFO] number of examples: 16415
[2019-06-25 13:44:08,468 INFO] Step 53900/300000; acc:  71.74; ppl:  3.62; xent: 1.29; lr: 0.00001; 10041/9624 tok/s;   4484 sec
[2019-06-25 13:44:49,810 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 13:44:49,952 INFO] number of examples: 16415
[2019-06-25 13:45:33,885 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 13:45:34,018 INFO] number of examples: 16415
[2019-06-25 13:46:04,388 INFO] Step 53950/300000; acc:  72.08; ppl:  3.56; xent: 1.27; lr: 0.00001; 10199/9765 tok/s;   4600 sec
[2019-06-25 13:46:15,659 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 13:46:15,809 INFO] number of examples: 16415
[2019-06-25 13:46:59,648 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 13:46:59,787 INFO] number of examples: 16415
[2019-06-25 13:47:41,399 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 13:47:41,594 INFO] number of examples: 16415
[2019-06-25 13:48:00,435 INFO] Step 54000/300000; acc:  72.12; ppl:  3.54; xent: 1.27; lr: 0.00001; 10128/9709 tok/s;   4716 sec
[2019-06-25 13:48:00,436 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.valid.0.pt
[2019-06-25 13:48:00,444 INFO] number of examples: 886
[2019-06-25 13:48:05,636 INFO] Validation perplexity: 47.8974
[2019-06-25 13:48:05,636 INFO] Validation accuracy: 42.7019
[2019-06-25 13:48:05,636 INFO] Stalled patience: 0/8
[2019-06-25 13:48:05,636 INFO] Training finished after stalled validations. Early Stop!
[2019-06-25 13:48:05,636 INFO] Best model found at step 52400
[2019-06-25 13:48:05,696 INFO] Saving checkpoint models/transformer-fr-en.tune_step_54000.pt
[2019-06-25 17:51:23,339 INFO] Loading checkpoint from models/transformer-fr-en_step_52000.pt
[2019-06-25 17:51:23,607 INFO] Loading vocab from checkpoint at models/transformer-fr-en_step_52000.pt.
[2019-06-25 17:51:23,607 INFO]  * src vocab size = 28666
[2019-06-25 17:51:23,607 INFO]  * tgt vocab size = 28666
[2019-06-25 17:51:23,607 INFO] Building model...
[2019-06-25 17:51:26,853 INFO] NMTModel(
  (encoder): TransformerEncoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(28666, 512, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1)
        )
      )
    )
    (transformer): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
    )
    (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
  )
  (decoder): TransformerDecoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(28666, 512, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1)
        )
      )
    )
    (transformer_layers): ModuleList(
      (0): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
      (1): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
      (2): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
      (3): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
      (4): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
      (5): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
    )
    (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
  )
  (generator): Sequential(
    (0): Linear(in_features=512, out_features=28666, bias=True)
    (1): Cast()
    (2): LogSoftmax()
  )
)
[2019-06-25 17:51:26,855 INFO] encoder: 33592320
[2019-06-25 17:51:26,855 INFO] decoder: 39930874
[2019-06-25 17:51:26,855 INFO] * number of parameters: 73523194
[2019-06-25 17:51:27,291 INFO] Starting training on GPU: [0]
[2019-06-25 17:51:27,291 INFO] Start training loop and validate every 50 steps...
[2019-06-25 17:51:27,292 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 17:51:27,430 INFO] number of examples: 16415
[2019-06-25 17:52:08,666 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 17:52:08,806 INFO] number of examples: 16415
[2019-06-25 17:52:52,248 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 17:52:52,372 INFO] number of examples: 16415
[2019-06-25 17:53:22,533 INFO] Step 52050/300000; acc:  58.53; ppl:  8.16; xent: 2.10; lr: 0.00001; 10263/9824 tok/s;    115 sec
[2019-06-25 17:53:22,534 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.valid.0.pt
[2019-06-25 17:53:22,541 INFO] number of examples: 886
[2019-06-25 17:53:27,999 INFO] Validation perplexity: 53.5177
[2019-06-25 17:53:27,999 INFO] Validation accuracy: 38.8523
[2019-06-25 17:53:28,000 INFO] Model is improving ppl: inf --> 53.5177.
[2019-06-25 17:53:28,000 INFO] Model is improving acc: -inf --> 38.8523.
[2019-06-25 17:53:28,061 INFO] Saving checkpoint models/transformer-fr-en.tune_step_52050.pt
[2019-06-25 17:53:40,201 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 17:53:40,357 INFO] number of examples: 16415
[2019-06-25 17:54:23,938 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 17:54:24,066 INFO] number of examples: 16415
[2019-06-25 17:55:07,725 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 17:55:07,909 INFO] number of examples: 16415
[2019-06-25 17:55:24,381 INFO] Step 52100/300000; acc:  61.00; ppl:  6.93; xent: 1.94; lr: 0.00001; 9641/9246 tok/s;    237 sec
[2019-06-25 17:55:24,382 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.valid.0.pt
[2019-06-25 17:55:24,390 INFO] number of examples: 886
[2019-06-25 17:55:29,586 INFO] Validation perplexity: 49.4831
[2019-06-25 17:55:29,586 INFO] Validation accuracy: 39.69
[2019-06-25 17:55:29,586 INFO] Model is improving ppl: 53.5177 --> 49.4831.
[2019-06-25 17:55:29,587 INFO] Model is improving acc: 38.8523 --> 39.69.
[2019-06-25 17:55:29,646 INFO] Saving checkpoint models/transformer-fr-en.tune_step_52100.pt
[2019-06-25 17:55:59,981 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 17:56:00,126 INFO] number of examples: 16415
[2019-06-25 17:56:44,146 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 17:56:44,341 INFO] number of examples: 16415
[2019-06-25 17:57:28,989 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 17:57:29,124 INFO] number of examples: 16415
[2019-06-25 17:57:31,690 INFO] Step 52150/300000; acc:  62.20; ppl:  6.47; xent: 1.87; lr: 0.00001; 9147/8772 tok/s;    364 sec
[2019-06-25 17:57:31,691 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.valid.0.pt
[2019-06-25 17:57:31,700 INFO] number of examples: 886
[2019-06-25 17:57:36,933 INFO] Validation perplexity: 48.1347
[2019-06-25 17:57:36,933 INFO] Validation accuracy: 40.081
[2019-06-25 17:57:36,933 INFO] Model is improving ppl: 49.4831 --> 48.1347.
[2019-06-25 17:57:36,933 INFO] Model is improving acc: 39.69 --> 40.081.
[2019-06-25 17:57:36,995 INFO] Saving checkpoint models/transformer-fr-en.tune_step_52150.pt
[2019-06-25 17:58:17,013 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 17:58:17,217 INFO] number of examples: 16415
[2019-06-25 17:59:01,983 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 17:59:02,137 INFO] number of examples: 16415
[2019-06-25 17:59:35,130 INFO] Step 52200/300000; acc:  63.12; ppl:  6.10; xent: 1.81; lr: 0.00001; 9527/9128 tok/s;    488 sec
[2019-06-25 17:59:35,131 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.valid.0.pt
[2019-06-25 17:59:35,140 INFO] number of examples: 886
[2019-06-25 17:59:40,369 INFO] Validation perplexity: 47.254
[2019-06-25 17:59:40,369 INFO] Validation accuracy: 40.2984
[2019-06-25 17:59:40,369 INFO] Model is improving ppl: 48.1347 --> 47.254.
[2019-06-25 17:59:40,369 INFO] Model is improving acc: 40.081 --> 40.2984.
[2019-06-25 17:59:40,431 INFO] Saving checkpoint models/transformer-fr-en.tune_step_52200.pt
[2019-06-25 17:59:54,654 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 17:59:54,782 INFO] number of examples: 16415
[2019-06-25 18:00:38,715 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 18:00:38,858 INFO] number of examples: 16415
[2019-06-25 18:01:22,564 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 18:01:22,695 INFO] number of examples: 16415
[2019-06-25 18:01:41,675 INFO] Step 52250/300000; acc:  63.72; ppl:  5.88; xent: 1.77; lr: 0.00001; 9333/8938 tok/s;    614 sec
[2019-06-25 18:01:41,676 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.valid.0.pt
[2019-06-25 18:01:41,684 INFO] number of examples: 886
[2019-06-25 18:01:47,101 INFO] Validation perplexity: 46.6242
[2019-06-25 18:01:47,101 INFO] Validation accuracy: 40.5417
[2019-06-25 18:01:47,101 INFO] Model is improving ppl: 47.254 --> 46.6242.
[2019-06-25 18:01:47,101 INFO] Model is improving acc: 40.2984 --> 40.5417.
[2019-06-25 18:01:47,163 INFO] Saving checkpoint models/transformer-fr-en.tune_step_52250.pt
[2019-06-25 18:02:11,325 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 18:02:11,477 INFO] number of examples: 16415
[2019-06-25 18:02:56,313 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 18:02:56,454 INFO] number of examples: 16415
[2019-06-25 18:03:40,761 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 18:03:40,964 INFO] number of examples: 16415
[2019-06-25 18:03:45,735 INFO] Step 52300/300000; acc:  64.21; ppl:  5.72; xent: 1.74; lr: 0.00001; 9352/8978 tok/s;    738 sec
[2019-06-25 18:03:45,736 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.valid.0.pt
[2019-06-25 18:03:45,745 INFO] number of examples: 886
[2019-06-25 18:03:51,017 INFO] Validation perplexity: 46.4184
[2019-06-25 18:03:51,017 INFO] Validation accuracy: 40.6714
[2019-06-25 18:03:51,017 INFO] Model is improving ppl: 46.6242 --> 46.4184.
[2019-06-25 18:03:51,017 INFO] Model is improving acc: 40.5417 --> 40.6714.
[2019-06-25 18:03:51,076 INFO] Saving checkpoint models/transformer-fr-en.tune_step_52300.pt
[2019-06-25 18:04:32,843 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 18:04:32,984 INFO] number of examples: 16415
[2019-06-25 18:05:16,826 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 18:05:16,956 INFO] number of examples: 16415
[2019-06-25 18:05:51,811 INFO] Step 52350/300000; acc:  64.75; ppl:  5.52; xent: 1.71; lr: 0.00001; 9312/8918 tok/s;    865 sec
[2019-06-25 18:05:51,812 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.valid.0.pt
[2019-06-25 18:05:51,821 INFO] number of examples: 886
[2019-06-25 18:05:57,043 INFO] Validation perplexity: 46.1228
[2019-06-25 18:05:57,044 INFO] Validation accuracy: 40.823
[2019-06-25 18:05:57,044 INFO] Model is improving ppl: 46.4184 --> 46.1228.
[2019-06-25 18:05:57,044 INFO] Model is improving acc: 40.6714 --> 40.823.
[2019-06-25 18:05:57,101 INFO] Saving checkpoint models/transformer-fr-en.tune_step_52350.pt
[2019-06-25 18:06:04,540 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 18:06:04,684 INFO] number of examples: 16415
[2019-06-25 18:06:48,420 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 18:06:48,553 INFO] number of examples: 16415
[2019-06-25 18:07:32,550 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 18:07:32,751 INFO] number of examples: 16415
[2019-06-25 18:07:54,350 INFO] Step 52400/300000; acc:  65.17; ppl:  5.37; xent: 1.68; lr: 0.00001; 9679/9265 tok/s;    987 sec
[2019-06-25 18:07:54,351 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.valid.0.pt
[2019-06-25 18:07:54,360 INFO] number of examples: 886
[2019-06-25 18:07:59,647 INFO] Validation perplexity: 45.8318
[2019-06-25 18:07:59,648 INFO] Validation accuracy: 41.0005
[2019-06-25 18:07:59,648 INFO] Model is improving ppl: 46.1228 --> 45.8318.
[2019-06-25 18:07:59,648 INFO] Model is improving acc: 40.823 --> 41.0005.
[2019-06-25 18:07:59,709 INFO] Saving checkpoint models/transformer-fr-en.tune_step_52400.pt
[2019-06-25 18:08:25,005 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 18:08:25,144 INFO] number of examples: 16415
[2019-06-25 18:09:08,859 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 18:09:09,052 INFO] number of examples: 16415
[2019-06-25 18:09:52,895 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 18:09:53,032 INFO] number of examples: 16415
[2019-06-25 18:10:00,262 INFO] Step 52450/300000; acc:  65.53; ppl:  5.27; xent: 1.66; lr: 0.00001; 9247/8875 tok/s;   1113 sec
[2019-06-25 18:10:00,263 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.valid.0.pt
[2019-06-25 18:10:00,271 INFO] number of examples: 886
[2019-06-25 18:10:05,489 INFO] Validation perplexity: 45.7994
[2019-06-25 18:10:05,489 INFO] Validation accuracy: 41.1182
[2019-06-25 18:10:05,490 INFO] Model is improving ppl: 45.8318 --> 45.7994.
[2019-06-25 18:10:05,490 INFO] Model is improving acc: 41.0005 --> 41.1182.
[2019-06-25 18:10:05,550 INFO] Saving checkpoint models/transformer-fr-en.tune_step_52450.pt
[2019-06-25 18:10:40,458 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 18:10:40,655 INFO] number of examples: 16415
[2019-06-25 18:11:24,409 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 18:11:24,548 INFO] number of examples: 16415
[2019-06-25 18:12:01,469 INFO] Step 52500/300000; acc:  65.86; ppl:  5.15; xent: 1.64; lr: 0.00001; 9622/9227 tok/s;   1234 sec
[2019-06-25 18:12:01,470 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.valid.0.pt
[2019-06-25 18:12:01,477 INFO] number of examples: 886
[2019-06-25 18:12:06,709 INFO] Validation perplexity: 45.7636
[2019-06-25 18:12:06,709 INFO] Validation accuracy: 41.1979
[2019-06-25 18:12:06,710 INFO] Model is improving ppl: 45.7994 --> 45.7636.
[2019-06-25 18:12:06,710 INFO] Model is improving acc: 41.1182 --> 41.1979.
[2019-06-25 18:12:06,769 INFO] Saving checkpoint models/transformer-fr-en.tune_step_52500.pt
[2019-06-25 18:12:16,366 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 18:12:16,499 INFO] number of examples: 16415
[2019-06-25 18:13:00,250 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 18:13:00,393 INFO] number of examples: 16415
[2019-06-25 18:13:44,204 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 18:13:44,337 INFO] number of examples: 16415
[2019-06-25 18:14:07,780 INFO] Step 52550/300000; acc:  66.25; ppl:  5.04; xent: 1.62; lr: 0.00001; 9389/8981 tok/s;   1360 sec
[2019-06-25 18:14:07,781 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.valid.0.pt
[2019-06-25 18:14:07,849 INFO] number of examples: 886
[2019-06-25 18:14:13,064 INFO] Validation perplexity: 46.0853
[2019-06-25 18:14:13,064 INFO] Validation accuracy: 41.2378
[2019-06-25 18:14:13,065 INFO] Stalled patience: 7/8
[2019-06-25 18:14:13,124 INFO] Saving checkpoint models/transformer-fr-en.tune_step_52550.pt
[2019-06-25 18:14:31,883 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 18:14:32,040 INFO] number of examples: 16415
[2019-06-25 18:15:15,800 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 18:15:15,937 INFO] number of examples: 16415
[2019-06-25 18:15:59,813 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 18:16:00,003 INFO] number of examples: 16415
[2019-06-25 18:16:09,473 INFO] Step 52600/300000; acc:  66.48; ppl:  4.96; xent: 1.60; lr: 0.00001; 9586/9204 tok/s;   1482 sec
[2019-06-25 18:16:09,474 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.valid.0.pt
[2019-06-25 18:16:09,484 INFO] number of examples: 886
[2019-06-25 18:16:14,691 INFO] Validation perplexity: 45.8815
[2019-06-25 18:16:14,691 INFO] Validation accuracy: 41.3735
[2019-06-25 18:16:14,691 INFO] Stalled patience: 6/8
[2019-06-25 18:16:14,751 INFO] Saving checkpoint models/transformer-fr-en.tune_step_52600.pt
[2019-06-25 18:16:51,665 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 18:16:51,805 INFO] number of examples: 16415
[2019-06-25 18:17:35,547 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 18:17:35,678 INFO] number of examples: 16415
[2019-06-25 18:18:15,044 INFO] Step 52650/300000; acc:  66.78; ppl:  4.87; xent: 1.58; lr: 0.00001; 9305/8905 tok/s;   1608 sec
[2019-06-25 18:18:15,045 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.valid.0.pt
[2019-06-25 18:18:15,054 INFO] number of examples: 886
[2019-06-25 18:18:20,273 INFO] Validation perplexity: 45.7101
[2019-06-25 18:18:20,273 INFO] Validation accuracy: 41.5151
[2019-06-25 18:18:20,274 INFO] Model is improving ppl: 45.7636 --> 45.7101.
[2019-06-25 18:18:20,274 INFO] Model is improving acc: 41.1979 --> 41.5151.
[2019-06-25 18:18:20,333 INFO] Saving checkpoint models/transformer-fr-en.tune_step_52650.pt
[2019-06-25 18:18:23,267 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 18:18:23,409 INFO] number of examples: 16415
[2019-06-25 18:19:07,128 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 18:19:07,261 INFO] number of examples: 16415
[2019-06-25 18:19:51,084 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 18:19:51,230 INFO] number of examples: 16415
[2019-06-25 18:20:16,911 INFO] Step 52700/300000; acc:  67.13; ppl:  4.76; xent: 1.56; lr: 0.00001; 9706/9300 tok/s;   1730 sec
[2019-06-25 18:20:16,912 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.valid.0.pt
[2019-06-25 18:20:16,921 INFO] number of examples: 886
[2019-06-25 18:20:22,149 INFO] Validation perplexity: 45.7112
[2019-06-25 18:20:22,150 INFO] Validation accuracy: 41.5669
[2019-06-25 18:20:22,150 INFO] Stalled patience: 7/8
[2019-06-25 18:20:22,209 INFO] Saving checkpoint models/transformer-fr-en.tune_step_52700.pt
[2019-06-25 18:20:43,019 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 18:20:43,153 INFO] number of examples: 16415
[2019-06-25 18:21:26,877 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 18:21:27,066 INFO] number of examples: 16415
[2019-06-25 18:22:10,898 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 18:22:11,042 INFO] number of examples: 16415
[2019-06-25 18:22:22,874 INFO] Step 52750/300000; acc:  67.29; ppl:  4.71; xent: 1.55; lr: 0.00001; 9267/8890 tok/s;   1856 sec
[2019-06-25 18:22:22,875 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.valid.0.pt
[2019-06-25 18:22:22,884 INFO] number of examples: 886
[2019-06-25 18:22:28,092 INFO] Validation perplexity: 45.8313
[2019-06-25 18:22:28,092 INFO] Validation accuracy: 41.6088
[2019-06-25 18:22:28,093 INFO] Stalled patience: 6/8
[2019-06-25 18:22:28,152 INFO] Saving checkpoint models/transformer-fr-en.tune_step_52750.pt
[2019-06-25 18:22:58,515 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 18:22:58,708 INFO] number of examples: 16415
[2019-06-25 18:23:42,461 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 18:23:42,598 INFO] number of examples: 16415
[2019-06-25 18:24:24,108 INFO] Step 52800/300000; acc:  67.58; ppl:  4.63; xent: 1.53; lr: 0.00001; 9597/9196 tok/s;   1977 sec
[2019-06-25 18:24:24,109 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.valid.0.pt
[2019-06-25 18:24:24,117 INFO] number of examples: 886
[2019-06-25 18:24:29,313 INFO] Validation perplexity: 46.1446
[2019-06-25 18:24:29,313 INFO] Validation accuracy: 41.6607
[2019-06-25 18:24:29,313 INFO] Stalled patience: 5/8
[2019-06-25 18:24:29,372 INFO] Saving checkpoint models/transformer-fr-en.tune_step_52800.pt
[2019-06-25 18:24:34,413 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 18:24:34,805 INFO] number of examples: 16415
[2019-06-25 18:25:18,524 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 18:25:18,664 INFO] number of examples: 16415
[2019-06-25 18:26:02,432 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 18:26:02,565 INFO] number of examples: 16415
[2019-06-25 18:26:30,592 INFO] Step 52850/300000; acc:  67.89; ppl:  4.55; xent: 1.51; lr: 0.00001; 9347/8944 tok/s;   2103 sec
[2019-06-25 18:26:30,593 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.valid.0.pt
[2019-06-25 18:26:30,602 INFO] number of examples: 886
[2019-06-25 18:26:35,788 INFO] Validation perplexity: 46.0372
[2019-06-25 18:26:35,788 INFO] Validation accuracy: 41.7624
[2019-06-25 18:26:35,788 INFO] Stalled patience: 4/8
[2019-06-25 18:26:35,848 INFO] Saving checkpoint models/transformer-fr-en.tune_step_52850.pt
[2019-06-25 18:26:50,100 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 18:26:50,247 INFO] number of examples: 16415
[2019-06-25 18:27:33,982 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 18:27:34,116 INFO] number of examples: 16415
[2019-06-25 18:28:17,922 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 18:28:18,111 INFO] number of examples: 16415
[2019-06-25 18:28:32,208 INFO] Step 52900/300000; acc:  68.07; ppl:  4.49; xent: 1.50; lr: 0.00001; 9659/9273 tok/s;   2225 sec
[2019-06-25 18:28:32,209 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.valid.0.pt
[2019-06-25 18:28:32,217 INFO] number of examples: 886
[2019-06-25 18:28:37,420 INFO] Validation perplexity: 45.8405
[2019-06-25 18:28:37,420 INFO] Validation accuracy: 41.8422
[2019-06-25 18:28:37,421 INFO] Stalled patience: 3/8
[2019-06-25 18:28:37,480 INFO] Saving checkpoint models/transformer-fr-en.tune_step_52900.pt
[2019-06-25 18:29:09,810 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 18:29:09,947 INFO] number of examples: 16415
[2019-06-25 18:29:53,697 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 18:29:53,889 INFO] number of examples: 16415
[2019-06-25 18:30:35,361 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 18:30:35,500 INFO] number of examples: 16415
[2019-06-25 18:30:37,897 INFO] Step 52950/300000; acc:  68.29; ppl:  4.45; xent: 1.49; lr: 0.00001; 9245/8862 tok/s;   2351 sec
[2019-06-25 18:30:37,898 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.valid.0.pt
[2019-06-25 18:30:37,907 INFO] number of examples: 886
[2019-06-25 18:30:43,113 INFO] Validation perplexity: 46.1804
[2019-06-25 18:30:43,113 INFO] Validation accuracy: 41.928
[2019-06-25 18:30:43,113 INFO] Stalled patience: 2/8
[2019-06-25 18:30:43,172 INFO] Saving checkpoint models/transformer-fr-en.tune_step_52950.pt
[2019-06-25 18:31:25,198 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 18:31:25,398 INFO] number of examples: 16415
[2019-06-25 18:32:09,193 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 18:32:09,336 INFO] number of examples: 16415
[2019-06-25 18:32:39,606 INFO] Step 53000/300000; acc:  68.57; ppl:  4.36; xent: 1.47; lr: 0.00001; 9718/9300 tok/s;   2472 sec
[2019-06-25 18:32:39,607 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.valid.0.pt
[2019-06-25 18:32:39,615 INFO] number of examples: 886
[2019-06-25 18:32:44,817 INFO] Validation perplexity: 46.2056
[2019-06-25 18:32:44,817 INFO] Validation accuracy: 41.9539
[2019-06-25 18:32:44,817 INFO] Stalled patience: 1/8
[2019-06-25 18:32:44,877 INFO] Saving checkpoint models/transformer-fr-en.tune_step_53000.pt
[2019-06-25 18:33:01,338 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 18:33:01,472 INFO] number of examples: 16415
[2019-06-25 18:33:45,271 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 18:33:45,417 INFO] number of examples: 16415
[2019-06-25 18:34:29,293 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 18:34:29,428 INFO] number of examples: 16415
[2019-06-25 18:34:45,897 INFO] Step 53050/300000; acc:  68.73; ppl:  4.32; xent: 1.46; lr: 0.00001; 9301/8921 tok/s;   2599 sec
[2019-06-25 18:34:45,897 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.valid.0.pt
[2019-06-25 18:34:45,906 INFO] number of examples: 886
[2019-06-25 18:34:51,121 INFO] Validation perplexity: 46.095
[2019-06-25 18:34:51,121 INFO] Validation accuracy: 42.0237
[2019-06-25 18:34:51,121 INFO] Stalled patience: 0/8
[2019-06-25 18:34:51,121 INFO] Training finished after stalled validations. Early Stop!
[2019-06-25 18:34:51,122 INFO] Best model found at step 52650
[2019-06-25 18:34:51,181 INFO] Saving checkpoint models/transformer-fr-en.tune_step_53050.pt
[2019-06-25 19:41:48,289 INFO] Loading checkpoint from models/transformer-fr-en_step_52000.pt
[2019-06-25 19:41:48,554 INFO] Loading vocab from checkpoint at models/transformer-fr-en_step_52000.pt.
[2019-06-25 19:41:48,554 INFO]  * src vocab size = 28666
[2019-06-25 19:41:48,555 INFO]  * tgt vocab size = 28666
[2019-06-25 19:41:48,555 INFO] Building model...
[2019-06-25 19:42:09,480 INFO] Loading checkpoint from models/transformer-fr-en_step_52000.pt
[2019-06-25 19:42:09,735 INFO] Loading vocab from checkpoint at models/transformer-fr-en_step_52000.pt.
[2019-06-25 19:42:09,736 INFO]  * src vocab size = 28666
[2019-06-25 19:42:09,736 INFO]  * tgt vocab size = 28666
[2019-06-25 19:42:09,736 INFO] Building model...
[2019-06-25 19:42:12,608 INFO] NMTModel(
  (encoder): TransformerEncoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(28666, 512, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1)
        )
      )
    )
    (transformer): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
    )
    (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
  )
  (decoder): TransformerDecoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(28666, 512, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1)
        )
      )
    )
    (transformer_layers): ModuleList(
      (0): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
      (1): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
      (2): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
      (3): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
      (4): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
      (5): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
    )
    (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
  )
  (generator): Sequential(
    (0): Linear(in_features=512, out_features=28666, bias=True)
    (1): Cast()
    (2): LogSoftmax()
  )
)
[2019-06-25 19:42:12,610 INFO] encoder: 33592320
[2019-06-25 19:42:12,610 INFO] decoder: 39930874
[2019-06-25 19:42:12,610 INFO] * number of parameters: 73523194
[2019-06-25 19:42:13,048 INFO] Starting training on GPU: [0]
[2019-06-25 19:42:13,048 INFO] Start training loop and validate every 50 steps...
[2019-06-25 19:42:13,049 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 19:42:13,185 INFO] number of examples: 16415
[2019-06-25 19:42:53,953 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 19:42:54,092 INFO] number of examples: 16415
[2019-06-25 19:43:37,433 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 19:43:37,561 INFO] number of examples: 16415
[2019-06-25 19:44:07,721 INFO] Step 52050/300000; acc:  66.99; ppl:  4.82; xent: 1.57; lr: 0.00039; 10314/9873 tok/s;    115 sec
[2019-06-25 19:44:07,722 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.valid.0.pt
[2019-06-25 19:44:07,729 INFO] number of examples: 886
[2019-06-25 19:44:13,115 INFO] Validation perplexity: 44.4267
[2019-06-25 19:44:13,115 INFO] Validation accuracy: 43.2404
[2019-06-25 19:44:13,115 INFO] Model is improving ppl: inf --> 44.4267.
[2019-06-25 19:44:13,115 INFO] Model is improving acc: -inf --> 43.2404.
[2019-06-25 19:44:13,174 INFO] Saving checkpoint models/transformer-fr-en.tune_step_52050.pt
[2019-06-25 19:44:25,035 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 19:44:25,190 INFO] number of examples: 16415
[2019-06-25 19:45:08,717 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 19:45:08,845 INFO] number of examples: 16415
[2019-06-25 19:45:52,408 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 19:45:52,594 INFO] number of examples: 16415
[2019-06-25 19:46:09,054 INFO] Step 52100/300000; acc:  75.18; ppl:  2.99; xent: 1.09; lr: 0.00039; 9682/9285 tok/s;    236 sec
[2019-06-25 19:46:09,055 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.valid.0.pt
[2019-06-25 19:46:09,063 INFO] number of examples: 886
[2019-06-25 19:46:14,227 INFO] Validation perplexity: 49.6328
[2019-06-25 19:46:14,227 INFO] Validation accuracy: 43.6951
[2019-06-25 19:46:14,227 INFO] Stalled patience: 7/8
[2019-06-25 19:46:14,286 INFO] Saving checkpoint models/transformer-fr-en.tune_step_52100.pt
[2019-06-25 19:46:39,823 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 19:46:39,954 INFO] number of examples: 16415
[2019-06-25 19:47:23,575 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 19:47:23,765 INFO] number of examples: 16415
[2019-06-25 19:48:07,505 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 19:48:07,643 INFO] number of examples: 16415
[2019-06-25 19:48:10,215 INFO] Step 52150/300000; acc:  79.04; ppl:  2.44; xent: 0.89; lr: 0.00039; 9612/9218 tok/s;    357 sec
[2019-06-25 19:48:10,216 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.valid.0.pt
[2019-06-25 19:48:10,225 INFO] number of examples: 886
[2019-06-25 19:48:15,426 INFO] Validation perplexity: 45.5599
[2019-06-25 19:48:15,427 INFO] Validation accuracy: 44.0482
[2019-06-25 19:48:15,427 INFO] Stalled patience: 6/8
[2019-06-25 19:48:15,485 INFO] Saving checkpoint models/transformer-fr-en.tune_step_52150.pt
[2019-06-25 19:48:54,939 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 19:48:55,132 INFO] number of examples: 16415
[2019-06-25 19:49:38,796 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 19:49:38,934 INFO] number of examples: 16415
[2019-06-25 19:50:11,344 INFO] Step 52200/300000; acc:  82.28; ppl:  2.09; xent: 0.74; lr: 0.00039; 9709/9302 tok/s;    478 sec
[2019-06-25 19:50:11,345 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.valid.0.pt
[2019-06-25 19:50:11,353 INFO] number of examples: 886
[2019-06-25 19:50:16,530 INFO] Validation perplexity: 64.2524
[2019-06-25 19:50:16,530 INFO] Validation accuracy: 43.2105
[2019-06-25 19:50:16,531 INFO] Decreasing patience: 7/8
[2019-06-25 19:50:16,589 INFO] Saving checkpoint models/transformer-fr-en.tune_step_52200.pt
[2019-06-25 19:50:26,289 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 19:50:26,422 INFO] number of examples: 16415
[2019-06-25 19:51:10,200 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 19:51:10,343 INFO] number of examples: 16415
[2019-06-25 19:51:54,079 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 19:51:54,214 INFO] number of examples: 16415
[2019-06-25 19:52:13,013 INFO] Step 52250/300000; acc:  84.85; ppl:  1.87; xent: 0.63; lr: 0.00039; 9707/9296 tok/s;    600 sec
[2019-06-25 19:52:13,014 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.valid.0.pt
[2019-06-25 19:52:13,022 INFO] number of examples: 886
[2019-06-25 19:52:18,234 INFO] Validation perplexity: 74.0502
[2019-06-25 19:52:18,234 INFO] Validation accuracy: 43.2264
[2019-06-25 19:52:18,235 INFO] Decreasing patience: 6/8
[2019-06-25 19:52:18,294 INFO] Saving checkpoint models/transformer-fr-en.tune_step_52250.pt
[2019-06-25 19:52:41,682 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 19:52:41,823 INFO] number of examples: 16415
[2019-06-25 19:53:25,508 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 19:53:25,643 INFO] number of examples: 16415
[2019-06-25 19:54:09,487 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 19:54:09,678 INFO] number of examples: 16415
[2019-06-25 19:54:14,425 INFO] Step 52300/300000; acc:  86.97; ppl:  1.72; xent: 0.54; lr: 0.00039; 9555/9174 tok/s;    721 sec
[2019-06-25 19:54:14,426 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.valid.0.pt
[2019-06-25 19:54:14,435 INFO] number of examples: 886
[2019-06-25 19:54:19,603 INFO] Validation perplexity: 71.4182
[2019-06-25 19:54:19,603 INFO] Validation accuracy: 42.9731
[2019-06-25 19:54:19,604 INFO] Decreasing patience: 5/8
[2019-06-25 19:54:19,663 INFO] Saving checkpoint models/transformer-fr-en.tune_step_52300.pt
[2019-06-25 19:54:56,986 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 19:54:57,125 INFO] number of examples: 16415
[2019-06-25 19:55:40,791 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 19:55:40,925 INFO] number of examples: 16415
[2019-06-25 19:56:15,689 INFO] Step 52350/300000; acc:  89.02; ppl:  1.59; xent: 0.46; lr: 0.00039; 9681/9272 tok/s;    843 sec
[2019-06-25 19:56:15,690 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.valid.0.pt
[2019-06-25 19:56:15,698 INFO] number of examples: 886
[2019-06-25 19:56:20,878 INFO] Validation perplexity: 87.6307
[2019-06-25 19:56:20,878 INFO] Validation accuracy: 42.6839
[2019-06-25 19:56:20,879 INFO] Decreasing patience: 4/8
[2019-06-25 19:56:20,938 INFO] Saving checkpoint models/transformer-fr-en.tune_step_52350.pt
[2019-06-25 19:56:28,371 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 19:56:28,514 INFO] number of examples: 16415
[2019-06-25 19:57:12,212 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 19:57:12,344 INFO] number of examples: 16415
[2019-06-25 19:57:56,114 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 19:57:56,300 INFO] number of examples: 16415
[2019-06-25 19:58:17,532 INFO] Step 52400/300000; acc:  90.77; ppl:  1.50; xent: 0.40; lr: 0.00039; 9734/9318 tok/s;    964 sec
[2019-06-25 19:58:17,533 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.valid.0.pt
[2019-06-25 19:58:17,542 INFO] number of examples: 886
[2019-06-25 19:58:22,750 INFO] Validation perplexity: 83.5635
[2019-06-25 19:58:22,750 INFO] Validation accuracy: 43.1008
[2019-06-25 19:58:22,751 INFO] Decreasing patience: 3/8
[2019-06-25 19:58:22,810 INFO] Saving checkpoint models/transformer-fr-en.tune_step_52400.pt
[2019-06-25 19:58:43,754 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 19:58:43,890 INFO] number of examples: 16415
[2019-06-25 19:59:27,618 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 19:59:27,807 INFO] number of examples: 16415
[2019-06-25 20:00:11,626 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 20:00:11,764 INFO] number of examples: 16415
[2019-06-25 20:00:18,994 INFO] Step 52450/300000; acc:  92.09; ppl:  1.43; xent: 0.36; lr: 0.00039; 9586/9200 tok/s;   1086 sec
[2019-06-25 20:00:18,995 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.valid.0.pt
[2019-06-25 20:00:19,004 INFO] number of examples: 886
[2019-06-25 20:00:24,210 INFO] Validation perplexity: 79.4127
[2019-06-25 20:00:24,210 INFO] Validation accuracy: 43.1247
[2019-06-25 20:00:24,210 INFO] Decreasing patience: 2/8
[2019-06-25 20:00:24,270 INFO] Saving checkpoint models/transformer-fr-en.tune_step_52450.pt
[2019-06-25 20:00:59,114 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 20:00:59,308 INFO] number of examples: 16415
[2019-06-25 20:01:43,059 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 20:01:43,199 INFO] number of examples: 16415
[2019-06-25 20:02:20,147 INFO] Step 52500/300000; acc:  93.22; ppl:  1.38; xent: 0.32; lr: 0.00039; 9627/9231 tok/s;   1207 sec
[2019-06-25 20:02:20,148 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.valid.0.pt
[2019-06-25 20:02:20,156 INFO] number of examples: 886
[2019-06-25 20:02:25,375 INFO] Validation perplexity: 111.271
[2019-06-25 20:02:25,375 INFO] Validation accuracy: 42.1613
[2019-06-25 20:02:25,375 INFO] Decreasing patience: 1/8
[2019-06-25 20:02:25,434 INFO] Saving checkpoint models/transformer-fr-en.tune_step_52500.pt
[2019-06-25 20:02:30,695 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 20:02:30,826 INFO] number of examples: 16415
[2019-06-25 20:03:15,002 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 20:03:15,149 INFO] number of examples: 16415
[2019-06-25 20:03:58,978 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.train.0.pt
[2019-06-25 20:03:59,112 INFO] number of examples: 16415
[2019-06-25 20:04:22,537 INFO] Step 52550/300000; acc:  94.15; ppl:  1.33; xent: 0.29; lr: 0.00039; 9690/9269 tok/s;   1329 sec
[2019-06-25 20:04:22,538 INFO] Loading dataset from ./data/onmt/transformer-fr-en.tune.valid.0.pt
[2019-06-25 20:04:22,606 INFO] number of examples: 886
[2019-06-25 20:04:27,820 INFO] Validation perplexity: 96.8136
[2019-06-25 20:04:27,820 INFO] Validation accuracy: 42.9472
[2019-06-25 20:04:27,820 INFO] Decreasing patience: 0/8
[2019-06-25 20:04:27,820 INFO] Training finished after not improving. Early Stop!
[2019-06-25 20:04:27,820 INFO] Best model found at step 52050
[2019-06-25 20:04:27,880 INFO] Saving checkpoint models/transformer-fr-en.tune_step_52550.pt
