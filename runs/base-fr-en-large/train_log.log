[2019-05-31 14:58:14,333 INFO]  * src vocab size = 16412
[2019-05-31 14:58:14,333 INFO]  * tgt vocab size = 16500
[2019-05-31 14:58:14,333 INFO] Building model...
[2019-05-31 14:58:17,931 INFO] NMTModel(
  (encoder): RNNEncoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(16412, 1024, padding_idx=1)
        )
      )
    )
    (rnn): LSTM(1024, 512, num_layers=4, dropout=0.3, bidirectional=True)
    (bridge): ModuleList(
      (0): Linear(in_features=2048, out_features=2048, bias=True)
      (1): Linear(in_features=2048, out_features=2048, bias=True)
    )
  )
  (decoder): InputFeedRNNDecoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(16500, 1024, padding_idx=1)
        )
      )
    )
    (dropout): Dropout(p=0.3)
    (rnn): StackedLSTM(
      (dropout): Dropout(p=0.3)
      (layers): ModuleList(
        (0): LSTMCell(2048, 1024)
        (1): LSTMCell(1024, 1024)
        (2): LSTMCell(1024, 1024)
        (3): LSTMCell(1024, 1024)
      )
    )
    (attn): GlobalAttention(
      (linear_context): Linear(in_features=1024, out_features=1024, bias=False)
      (linear_query): Linear(in_features=1024, out_features=1024, bias=True)
      (v): Linear(in_features=1024, out_features=1, bias=False)
      (linear_out): Linear(in_features=2048, out_features=1024, bias=True)
    )
  )
  (generator): Sequential(
    (0): Linear(in_features=1024, out_features=16500, bias=True)
    (1): Cast()
    (2): LogSoftmax()
  )
)
[2019-05-31 14:58:17,932 INFO] encoder: 50397184
[2019-05-31 14:58:17,932 INFO] decoder: 75787380
[2019-05-31 14:58:17,932 INFO] * number of parameters: 126184564
[2019-05-31 14:58:18,055 INFO] Starting training on GPU: [0]
[2019-05-31 14:58:18,055 INFO] Start training loop and validate every 5000 steps...
[2019-05-31 14:58:29,506 INFO] Loading dataset from ./data/onmt-vocab/fr-en.large.train.0.pt, number of examples: 951312
[2019-05-31 15:02:54,603 INFO] Step 500/150000; acc:  17.48; ppl: 148.35; xent: 5.00; lr: 0.00100; 6622/6120 tok/s;    277 sec
[2019-05-31 15:07:19,971 INFO] Step 1000/150000; acc:  36.58; ppl: 34.82; xent: 3.55; lr: 0.00100; 6896/6377 tok/s;    542 sec
[2019-05-31 15:11:40,739 INFO] Step 1500/150000; acc:  46.94; ppl: 17.22; xent: 2.85; lr: 0.00100; 6936/6456 tok/s;    803 sec
[2019-05-31 15:15:58,935 INFO] Step 2000/150000; acc:  51.11; ppl: 12.77; xent: 2.55; lr: 0.00100; 7018/6416 tok/s;   1061 sec
[2019-05-31 15:20:23,635 INFO] Step 2500/150000; acc:  53.57; ppl: 10.64; xent: 2.36; lr: 0.00100; 6912/6364 tok/s;   1326 sec
[2019-05-31 15:24:48,683 INFO] Step 3000/150000; acc:  55.14; ppl:  9.45; xent: 2.25; lr: 0.00100; 6881/6290 tok/s;   1591 sec
[2019-05-31 15:29:12,824 INFO] Step 3500/150000; acc:  56.81; ppl:  8.42; xent: 2.13; lr: 0.00100; 6914/6371 tok/s;   1855 sec
[2019-05-31 15:33:37,062 INFO] Step 4000/150000; acc:  57.91; ppl:  7.79; xent: 2.05; lr: 0.00100; 6923/6419 tok/s;   2119 sec
[2019-05-31 15:37:59,256 INFO] Step 4500/150000; acc:  58.31; ppl:  7.55; xent: 2.02; lr: 0.00100; 6960/6389 tok/s;   2381 sec
[2019-05-31 15:42:20,690 INFO] Step 5000/150000; acc:  58.91; ppl:  7.20; xent: 1.97; lr: 0.00100; 6990/6399 tok/s;   2643 sec
[2019-05-31 15:42:20,697 INFO] Loading dataset from ./data/onmt-vocab/fr-en.large.valid.0.pt, number of examples: 1500
[2019-05-31 15:42:30,928 INFO] Validation perplexity: 25.4651
[2019-05-31 15:42:30,928 INFO] Validation accuracy: 46.6499
[2019-05-31 15:42:30,933 INFO] Model is improving ppl: inf --> 25.4651.
[2019-05-31 15:42:30,933 INFO] Model is improving acc: -inf --> 46.6499.
[2019-05-31 15:42:30,933 INFO] Saving checkpoint models/fr-en.large_step_5000.pt
[2019-05-31 15:46:53,164 INFO] Step 5500/150000; acc:  59.67; ppl:  6.84; xent: 1.92; lr: 0.00100; 6669/6152 tok/s;   2915 sec
[2019-05-31 15:51:14,236 INFO] Step 6000/150000; acc:  60.20; ppl:  6.59; xent: 1.89; lr: 0.00100; 6966/6433 tok/s;   3176 sec
[2019-05-31 15:55:31,933 INFO] Step 6500/150000; acc:  60.90; ppl:  6.32; xent: 1.84; lr: 0.00100; 7072/6525 tok/s;   3434 sec
[2019-05-31 15:59:52,452 INFO] Step 7000/150000; acc:  61.48; ppl:  6.10; xent: 1.81; lr: 0.00100; 7026/6503 tok/s;   3694 sec
[2019-05-31 16:04:12,066 INFO] Step 7500/150000; acc:  61.30; ppl:  6.14; xent: 1.82; lr: 0.00100; 7019/6422 tok/s;   3954 sec
[2019-05-31 16:07:41,180 INFO] Loading dataset from ./data/onmt-vocab/fr-en.large.train.1.pt, number of examples: 951214
[2019-05-31 16:08:54,947 INFO] Step 8000/150000; acc:  62.06; ppl:  5.88; xent: 1.77; lr: 0.00100; 6162/5705 tok/s;   4237 sec
[2019-05-31 16:13:18,717 INFO] Step 8500/150000; acc:  62.00; ppl:  5.85; xent: 1.77; lr: 0.00100; 6910/6421 tok/s;   4501 sec
[2019-05-31 16:17:41,398 INFO] Step 9000/150000; acc:  62.46; ppl:  5.71; xent: 1.74; lr: 0.00100; 6937/6415 tok/s;   4763 sec
[2019-05-31 16:22:01,658 INFO] Step 9500/150000; acc:  62.80; ppl:  5.56; xent: 1.72; lr: 0.00100; 6960/6449 tok/s;   5024 sec
[2019-05-31 16:26:22,261 INFO] Step 10000/150000; acc:  63.10; ppl:  5.48; xent: 1.70; lr: 0.00100; 7010/6374 tok/s;   5284 sec
[2019-05-31 16:26:22,270 INFO] Loading dataset from ./data/onmt-vocab/fr-en.large.valid.0.pt, number of examples: 1500
[2019-05-31 16:26:36,970 INFO] Validation perplexity: 18.2962
[2019-05-31 16:26:36,970 INFO] Validation accuracy: 50.5027
[2019-05-31 16:26:36,970 INFO] Model is improving ppl: 25.4651 --> 18.2962.
[2019-05-31 16:26:36,970 INFO] Model is improving acc: 46.6499 --> 50.5027.
[2019-05-31 16:26:36,970 INFO] Saving checkpoint models/fr-en.large_step_10000.pt
[2019-05-31 16:30:58,528 INFO] Step 10500/150000; acc:  63.00; ppl:  5.49; xent: 1.70; lr: 0.00100; 6591/6044 tok/s;   5560 sec
[2019-05-31 16:35:33,329 INFO] Step 11000/150000; acc:  63.37; ppl:  5.36; xent: 1.68; lr: 0.00100; 6640/6100 tok/s;   5835 sec
[2019-05-31 16:40:10,935 INFO] Step 11500/150000; acc:  63.59; ppl:  5.28; xent: 1.66; lr: 0.00100; 6608/6080 tok/s;   6113 sec
[2019-05-31 16:44:48,814 INFO] Step 12000/150000; acc:  63.75; ppl:  5.25; xent: 1.66; lr: 0.00100; 6565/6086 tok/s;   6391 sec
[2019-05-31 16:49:28,262 INFO] Step 12500/150000; acc:  63.82; ppl:  5.22; xent: 1.65; lr: 0.00100; 6528/5964 tok/s;   6670 sec
[2019-05-31 16:54:02,463 INFO] Step 13000/150000; acc:  64.18; ppl:  5.11; xent: 1.63; lr: 0.00100; 6661/6070 tok/s;   6944 sec
[2019-05-31 16:58:33,827 INFO] Step 13500/150000; acc:  64.17; ppl:  5.10; xent: 1.63; lr: 0.00100; 6693/6207 tok/s;   7216 sec
[2019-05-31 17:03:09,027 INFO] Step 14000/150000; acc:  64.44; ppl:  5.01; xent: 1.61; lr: 0.00100; 6645/6115 tok/s;   7491 sec
[2019-05-31 17:07:42,052 INFO] Step 14500/150000; acc:  64.70; ppl:  4.96; xent: 1.60; lr: 0.00100; 6644/6138 tok/s;   7764 sec
[2019-05-31 17:12:01,819 INFO] Step 15000/150000; acc:  64.76; ppl:  4.90; xent: 1.59; lr: 0.00100; 7051/6550 tok/s;   8024 sec
[2019-05-31 17:12:01,828 INFO] Loading dataset from ./data/onmt-vocab/fr-en.large.valid.0.pt, number of examples: 1500
[2019-05-31 17:12:19,623 INFO] Validation perplexity: 15.0824
[2019-05-31 17:12:19,623 INFO] Validation accuracy: 52.9598
[2019-05-31 17:12:19,623 INFO] Model is improving ppl: 18.2962 --> 15.0824.
[2019-05-31 17:12:19,623 INFO] Model is improving acc: 50.5027 --> 52.9598.
[2019-05-31 17:12:19,624 INFO] Saving checkpoint models/fr-en.large_step_15000.pt
[2019-05-31 17:17:00,457 INFO] Step 15500/150000; acc:  64.60; ppl:  4.96; xent: 1.60; lr: 0.00100; 6005/5517 tok/s;   8322 sec
[2019-05-31 17:19:16,013 INFO] Loading dataset from ./data/onmt-vocab/fr-en.large.train.2.pt, number of examples: 197758
[2019-05-31 17:21:42,801 INFO] Step 16000/150000; acc:  64.71; ppl:  4.91; xent: 1.59; lr: 0.00100; 6160/5723 tok/s;   8605 sec
[2019-05-31 17:26:21,632 INFO] Step 16500/150000; acc:  65.02; ppl:  4.83; xent: 1.58; lr: 0.00100; 6511/5990 tok/s;   8884 sec
[2019-05-31 17:30:39,081 INFO] Step 17000/150000; acc:  65.30; ppl:  4.76; xent: 1.56; lr: 0.00100; 6959/6379 tok/s;   9141 sec
[2019-05-31 17:34:12,448 INFO] Loading dataset from ./data/onmt-vocab/fr-en.large.train.0.pt, number of examples: 951312
[2019-05-31 17:35:14,532 INFO] Step 17500/150000; acc:  65.37; ppl:  4.73; xent: 1.55; lr: 0.00100; 6576/6086 tok/s;   9416 sec
[2019-05-31 17:39:34,962 INFO] Step 18000/150000; acc:  65.16; ppl:  4.77; xent: 1.56; lr: 0.00100; 7054/6482 tok/s;   9677 sec
[2019-05-31 17:43:57,418 INFO] Step 18500/150000; acc:  65.38; ppl:  4.72; xent: 1.55; lr: 0.00100; 6921/6424 tok/s;   9939 sec
[2019-05-31 17:48:19,006 INFO] Step 19000/150000; acc:  65.64; ppl:  4.65; xent: 1.54; lr: 0.00100; 6910/6381 tok/s;  10201 sec
[2019-05-31 17:52:59,346 INFO] Step 19500/150000; acc:  65.49; ppl:  4.68; xent: 1.54; lr: 0.00100; 6475/5973 tok/s;  10481 sec
[2019-05-31 17:57:41,325 INFO] Step 20000/150000; acc:  65.82; ppl:  4.59; xent: 1.52; lr: 0.00100; 6532/5996 tok/s;  10763 sec
[2019-05-31 17:57:41,335 INFO] Loading dataset from ./data/onmt-vocab/fr-en.large.valid.0.pt, number of examples: 1500
[2019-05-31 17:57:57,677 INFO] Validation perplexity: 12.911
[2019-05-31 17:57:57,677 INFO] Validation accuracy: 55.2957
[2019-05-31 17:57:57,677 INFO] Model is improving ppl: 15.0824 --> 12.911.
[2019-05-31 17:57:57,677 INFO] Model is improving acc: 52.9598 --> 55.2957.
[2019-05-31 17:57:57,678 INFO] Saving checkpoint models/fr-en.large_step_20000.pt
[2019-05-31 18:02:40,433 INFO] Step 20500/150000; acc:  65.74; ppl:  4.61; xent: 1.53; lr: 0.00100; 6083/5580 tok/s;  11062 sec
[2019-05-31 18:07:15,533 INFO] Step 21000/150000; acc:  66.00; ppl:  4.55; xent: 1.52; lr: 0.00100; 6623/6092 tok/s;  11337 sec
[2019-05-31 18:11:57,254 INFO] Step 21500/150000; acc:  66.17; ppl:  4.50; xent: 1.50; lr: 0.00100; 6494/6011 tok/s;  11619 sec
[2019-05-31 18:16:34,609 INFO] Step 22000/150000; acc:  65.81; ppl:  4.57; xent: 1.52; lr: 0.00100; 6592/6057 tok/s;  11897 sec
[2019-05-31 18:21:07,918 INFO] Step 22500/150000; acc:  66.09; ppl:  4.51; xent: 1.51; lr: 0.00100; 6674/6095 tok/s;  12170 sec
[2019-05-31 18:25:37,314 INFO] Step 23000/150000; acc:  66.16; ppl:  4.48; xent: 1.50; lr: 0.00100; 6743/6275 tok/s;  12439 sec
[2019-05-31 18:30:11,104 INFO] Step 23500/150000; acc:  66.49; ppl:  4.40; xent: 1.48; lr: 0.00100; 6640/6108 tok/s;  12713 sec
[2019-05-31 18:34:37,983 INFO] Step 24000/150000; acc:  66.42; ppl:  4.42; xent: 1.49; lr: 0.00100; 6850/6300 tok/s;  12980 sec
[2019-05-31 18:39:00,024 INFO] Step 24500/150000; acc:  66.43; ppl:  4.42; xent: 1.49; lr: 0.00100; 6968/6422 tok/s;  13242 sec
[2019-05-31 18:43:22,718 INFO] Step 25000/150000; acc:  66.62; ppl:  4.37; xent: 1.48; lr: 0.00100; 6850/6303 tok/s;  13505 sec
[2019-05-31 18:43:22,728 INFO] Loading dataset from ./data/onmt-vocab/fr-en.large.valid.0.pt, number of examples: 1500
[2019-05-31 18:43:38,290 INFO] Validation perplexity: 12.5648
[2019-05-31 18:43:38,291 INFO] Validation accuracy: 55.5707
[2019-05-31 18:43:38,291 INFO] Model is improving ppl: 12.911 --> 12.5648.
[2019-05-31 18:43:38,291 INFO] Model is improving acc: 55.2957 --> 55.5707.
[2019-05-31 18:43:38,292 INFO] Saving checkpoint models/fr-en.large_step_25000.pt
[2019-05-31 18:46:06,793 INFO] Loading dataset from ./data/onmt-vocab/fr-en.large.train.1.pt, number of examples: 951214
[2019-05-31 18:48:20,756 INFO] Step 25500/150000; acc:  66.24; ppl:  4.45; xent: 1.49; lr: 0.00100; 5898/5476 tok/s;  13803 sec
[2019-05-31 18:52:45,765 INFO] Step 26000/150000; acc:  66.62; ppl:  4.37; xent: 1.47; lr: 0.00100; 6903/6359 tok/s;  14068 sec
[2019-05-31 18:57:06,518 INFO] Step 26500/150000; acc:  66.75; ppl:  4.33; xent: 1.47; lr: 0.00100; 7008/6522 tok/s;  14328 sec
[2019-05-31 19:01:21,285 INFO] Step 27000/150000; acc:  66.95; ppl:  4.29; xent: 1.46; lr: 0.00100; 7114/6542 tok/s;  14583 sec
[2019-05-31 19:05:40,578 INFO] Step 27500/150000; acc:  66.77; ppl:  4.32; xent: 1.46; lr: 0.00100; 7008/6409 tok/s;  14843 sec
[2019-05-31 19:10:02,145 INFO] Step 28000/150000; acc:  66.65; ppl:  4.35; xent: 1.47; lr: 0.00100; 6989/6378 tok/s;  15104 sec
[2019-05-31 19:14:22,494 INFO] Step 28500/150000; acc:  66.95; ppl:  4.27; xent: 1.45; lr: 0.00100; 7008/6456 tok/s;  15364 sec
[2019-05-31 19:18:43,987 INFO] Step 29000/150000; acc:  66.96; ppl:  4.27; xent: 1.45; lr: 0.00100; 7022/6470 tok/s;  15626 sec
[2019-05-31 19:23:08,203 INFO] Step 29500/150000; acc:  66.86; ppl:  4.29; xent: 1.46; lr: 0.00100; 6877/6378 tok/s;  15890 sec
[2019-05-31 19:27:29,274 INFO] Step 30000/150000; acc:  67.08; ppl:  4.24; xent: 1.45; lr: 0.00050; 7027/6398 tok/s;  16151 sec
[2019-05-31 19:27:29,282 INFO] Loading dataset from ./data/onmt-vocab/fr-en.large.valid.0.pt, number of examples: 1500
[2019-05-31 19:27:43,917 INFO] Validation perplexity: 11.9654
[2019-05-31 19:27:43,917 INFO] Validation accuracy: 55.9314
[2019-05-31 19:27:43,918 INFO] Model is improving ppl: 12.5648 --> 11.9654.
[2019-05-31 19:27:43,918 INFO] Model is improving acc: 55.5707 --> 55.9314.
[2019-05-31 19:27:43,918 INFO] Saving checkpoint models/fr-en.large_step_30000.pt
[2019-05-31 19:32:05,900 INFO] Step 30500/150000; acc:  67.68; ppl:  4.10; xent: 1.41; lr: 0.00050; 6592/6019 tok/s;  16428 sec
[2019-05-31 19:36:25,313 INFO] Step 31000/150000; acc:  67.76; ppl:  4.08; xent: 1.41; lr: 0.00050; 7002/6496 tok/s;  16687 sec
[2019-05-31 19:40:43,175 INFO] Step 31500/150000; acc:  68.14; ppl:  4.00; xent: 1.39; lr: 0.00050; 7051/6526 tok/s;  16945 sec
[2019-05-31 19:45:01,961 INFO] Step 32000/150000; acc:  68.08; ppl:  4.01; xent: 1.39; lr: 0.00050; 7038/6505 tok/s;  17204 sec
[2019-05-31 19:49:23,790 INFO] Step 32500/150000; acc:  68.27; ppl:  3.95; xent: 1.37; lr: 0.00050; 6986/6462 tok/s;  17466 sec
[2019-05-31 19:53:51,793 INFO] Step 33000/150000; acc:  68.16; ppl:  3.97; xent: 1.38; lr: 0.00050; 6597/6056 tok/s;  17734 sec
[2019-05-31 19:55:00,862 INFO] Loading dataset from ./data/onmt-vocab/fr-en.large.train.2.pt, number of examples: 197758
[2019-05-31 19:58:21,367 INFO] Step 33500/150000; acc:  68.00; ppl:  4.00; xent: 1.39; lr: 0.00050; 6539/6087 tok/s;  18003 sec
[2019-05-31 20:02:44,677 INFO] Step 34000/150000; acc:  68.52; ppl:  3.90; xent: 1.36; lr: 0.00050; 6874/6301 tok/s;  18267 sec
[2019-05-31 20:07:04,707 INFO] Step 34500/150000; acc:  68.55; ppl:  3.88; xent: 1.36; lr: 0.00050; 6938/6333 tok/s;  18527 sec
[2019-05-31 20:09:37,795 INFO] Loading dataset from ./data/onmt-vocab/fr-en.large.train.0.pt, number of examples: 951312
[2019-05-31 20:11:39,828 INFO] Step 35000/150000; acc:  68.44; ppl:  3.91; xent: 1.36; lr: 0.00050; 6570/6119 tok/s;  18802 sec
[2019-05-31 20:11:39,835 INFO] Loading dataset from ./data/onmt-vocab/fr-en.large.valid.0.pt, number of examples: 1500
[2019-05-31 20:11:54,501 INFO] Validation perplexity: 10.4664
[2019-05-31 20:11:54,502 INFO] Validation accuracy: 58.0692
[2019-05-31 20:11:54,502 INFO] Model is improving ppl: 11.9654 --> 10.4664.
[2019-05-31 20:11:54,502 INFO] Model is improving acc: 55.9314 --> 58.0692.
[2019-05-31 20:11:54,502 INFO] Saving checkpoint models/fr-en.large_step_35000.pt
[2019-05-31 20:16:15,972 INFO] Step 35500/150000; acc:  68.54; ppl:  3.88; xent: 1.36; lr: 0.00050; 6669/6113 tok/s;  19078 sec
[2019-05-31 20:20:39,992 INFO] Step 36000/150000; acc:  68.59; ppl:  3.86; xent: 1.35; lr: 0.00050; 6878/6399 tok/s;  19342 sec
[2019-05-31 20:24:54,968 INFO] Step 36500/150000; acc:  68.64; ppl:  3.86; xent: 1.35; lr: 0.00050; 7088/6489 tok/s;  19597 sec
[2019-05-31 20:29:19,695 INFO] Step 37000/150000; acc:  68.55; ppl:  3.87; xent: 1.35; lr: 0.00050; 6871/6367 tok/s;  19862 sec
[2019-05-31 20:33:42,500 INFO] Step 37500/150000; acc:  68.75; ppl:  3.82; xent: 1.34; lr: 0.00050; 6966/6408 tok/s;  20124 sec
[2019-05-31 20:38:02,260 INFO] Step 38000/150000; acc:  68.79; ppl:  3.83; xent: 1.34; lr: 0.00050; 7017/6432 tok/s;  20384 sec
[2019-05-31 20:42:21,156 INFO] Step 38500/150000; acc:  68.83; ppl:  3.81; xent: 1.34; lr: 0.00050; 7049/6503 tok/s;  20643 sec
[2019-05-31 20:46:44,491 INFO] Step 39000/150000; acc:  68.82; ppl:  3.82; xent: 1.34; lr: 0.00050; 6933/6431 tok/s;  20906 sec
[2019-05-31 20:51:07,312 INFO] Step 39500/150000; acc:  68.86; ppl:  3.80; xent: 1.33; lr: 0.00050; 6995/6369 tok/s;  21169 sec
[2019-05-31 20:54:02,622 INFO]  * src vocab size = 16412
[2019-05-31 20:54:02,623 INFO]  * tgt vocab size = 16500
[2019-05-31 20:54:02,623 INFO] Building model...
[2019-05-31 20:54:06,257 INFO] NMTModel(
  (encoder): RNNEncoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(16412, 1024, padding_idx=1)
        )
      )
    )
    (rnn): LSTM(1024, 512, num_layers=4, dropout=0.3, bidirectional=True)
    (bridge): ModuleList(
      (0): Linear(in_features=2048, out_features=2048, bias=True)
      (1): Linear(in_features=2048, out_features=2048, bias=True)
    )
  )
  (decoder): InputFeedRNNDecoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(16500, 1024, padding_idx=1)
        )
      )
    )
    (dropout): Dropout(p=0.3)
    (rnn): StackedLSTM(
      (dropout): Dropout(p=0.3)
      (layers): ModuleList(
        (0): LSTMCell(2048, 1024)
        (1): LSTMCell(1024, 1024)
        (2): LSTMCell(1024, 1024)
        (3): LSTMCell(1024, 1024)
      )
    )
    (attn): GlobalAttention(
      (linear_context): Linear(in_features=1024, out_features=1024, bias=False)
      (linear_query): Linear(in_features=1024, out_features=1024, bias=True)
      (v): Linear(in_features=1024, out_features=1, bias=False)
      (linear_out): Linear(in_features=2048, out_features=1024, bias=True)
    )
  )
  (generator): Sequential(
    (0): Linear(in_features=1024, out_features=16500, bias=True)
    (1): Cast()
    (2): LogSoftmax()
  )
)
[2019-05-31 20:54:06,258 INFO] encoder: 50397184
[2019-05-31 20:54:06,258 INFO] decoder: 75787380
[2019-05-31 20:54:06,258 INFO] * number of parameters: 126184564
[2019-05-31 20:54:06,378 INFO] Starting training on GPU: [0]
[2019-05-31 20:54:06,378 INFO] Start training loop and validate every 5000 steps...
[2019-05-31 20:54:18,177 INFO] Loading dataset from ./data/onmt-vocab/fr-en.large.train.0.pt, number of examples: 951312
[2019-05-31 20:58:42,511 INFO] Step 500/150000; acc:  16.20; ppl: 159.94; xent: 5.07; lr: 0.00100; 6632/6129 tok/s;    276 sec
[2019-05-31 21:03:05,688 INFO] Step 1000/150000; acc:  33.59; ppl: 41.68; xent: 3.73; lr: 0.00100; 6953/6430 tok/s;    539 sec
[2019-05-31 21:07:22,924 INFO] Step 1500/150000; acc:  45.38; ppl: 19.06; xent: 2.95; lr: 0.00100; 7031/6545 tok/s;    797 sec
[2019-05-31 21:11:41,196 INFO] Step 2000/150000; acc:  50.38; ppl: 13.44; xent: 2.60; lr: 0.00100; 7016/6414 tok/s;   1055 sec
[2019-05-31 21:16:03,982 INFO] Step 2500/150000; acc:  53.04; ppl: 11.01; xent: 2.40; lr: 0.00100; 6963/6410 tok/s;   1318 sec
[2019-05-31 21:20:26,404 INFO] Step 3000/150000; acc:  54.81; ppl:  9.64; xent: 2.27; lr: 0.00100; 6950/6353 tok/s;   1580 sec
[2019-05-31 21:24:44,713 INFO] Step 3500/150000; acc:  56.60; ppl:  8.54; xent: 2.14; lr: 0.00100; 7070/6515 tok/s;   1838 sec
[2019-05-31 21:29:05,265 INFO] Step 4000/150000; acc:  57.72; ppl:  7.88; xent: 2.06; lr: 0.00100; 7021/6510 tok/s;   2099 sec
[2019-05-31 21:33:27,521 INFO] Step 4500/150000; acc:  58.20; ppl:  7.60; xent: 2.03; lr: 0.00100; 6958/6388 tok/s;   2361 sec
[2019-05-31 21:37:50,208 INFO] Step 5000/150000; acc:  58.82; ppl:  7.23; xent: 1.98; lr: 0.00100; 6957/6368 tok/s;   2624 sec
[2019-05-31 21:37:50,216 INFO] Loading dataset from ./data/onmt-vocab/fr-en.large.valid.0.pt, number of examples: 1500
[2019-05-31 21:38:00,487 INFO] Validation perplexity: 25.7372
[2019-05-31 21:38:00,487 INFO] Validation accuracy: 46.5494
[2019-05-31 21:38:00,487 INFO] Model is improving ppl: inf --> 25.7372.
[2019-05-31 21:38:00,487 INFO] Model is improving acc: -inf --> 46.5494.
[2019-05-31 21:38:00,488 INFO] Saving checkpoint models/fr-en.large_step_5000.pt
[2019-05-31 21:42:22,771 INFO] Step 5500/150000; acc:  59.68; ppl:  6.86; xent: 1.93; lr: 0.00100; 6667/6150 tok/s;   2896 sec
[2019-05-31 21:46:41,963 INFO] Step 6000/150000; acc:  60.22; ppl:  6.60; xent: 1.89; lr: 0.00100; 7017/6480 tok/s;   3156 sec
[2019-05-31 21:51:06,199 INFO] Step 6500/150000; acc:  60.86; ppl:  6.34; xent: 1.85; lr: 0.00100; 6897/6364 tok/s;   3420 sec
[2019-05-31 21:55:27,742 INFO] Step 7000/150000; acc:  61.48; ppl:  6.11; xent: 1.81; lr: 0.00100; 6999/6477 tok/s;   3681 sec
[2019-05-31 21:59:48,807 INFO] Step 7500/150000; acc:  61.30; ppl:  6.15; xent: 1.82; lr: 0.00100; 6980/6386 tok/s;   3942 sec
[2019-05-31 22:03:19,387 INFO] Loading dataset from ./data/onmt-vocab/fr-en.large.train.1.pt, number of examples: 951214
[2019-05-31 22:04:33,245 INFO] Step 8000/150000; acc:  62.03; ppl:  5.88; xent: 1.77; lr: 0.00100; 6128/5674 tok/s;   4227 sec
[2019-05-31 22:08:55,964 INFO] Step 8500/150000; acc:  61.97; ppl:  5.86; xent: 1.77; lr: 0.00100; 6938/6447 tok/s;   4490 sec
[2019-05-31 22:13:16,263 INFO] Step 9000/150000; acc:  62.50; ppl:  5.70; xent: 1.74; lr: 0.00100; 7001/6474 tok/s;   4750 sec
[2019-05-31 22:17:32,034 INFO] Step 9500/150000; acc:  62.83; ppl:  5.57; xent: 1.72; lr: 0.00100; 7082/6562 tok/s;   5006 sec
[2019-05-31 22:21:50,885 INFO] Step 10000/150000; acc:  63.10; ppl:  5.48; xent: 1.70; lr: 0.00100; 7057/6417 tok/s;   5265 sec
[2019-05-31 22:21:50,893 INFO] Loading dataset from ./data/onmt-vocab/fr-en.large.valid.0.pt, number of examples: 1500
[2019-05-31 22:22:05,545 INFO] Validation perplexity: 18.1682
[2019-05-31 22:22:05,546 INFO] Validation accuracy: 50.7126
[2019-05-31 22:22:05,546 INFO] Model is improving ppl: 25.7372 --> 18.1682.
[2019-05-31 22:22:05,546 INFO] Model is improving acc: 46.5494 --> 50.7126.
[2019-05-31 22:22:05,546 INFO] Saving checkpoint models/fr-en.large_step_10000.pt
[2019-05-31 22:26:27,515 INFO] Step 10500/150000; acc:  63.02; ppl:  5.49; xent: 1.70; lr: 0.00100; 6582/6036 tok/s;   5541 sec
[2019-05-31 22:30:49,693 INFO] Step 11000/150000; acc:  63.37; ppl:  5.37; xent: 1.68; lr: 0.00100; 6960/6394 tok/s;   5803 sec
[2019-05-31 22:35:08,615 INFO] Step 11500/150000; acc:  63.57; ppl:  5.30; xent: 1.67; lr: 0.00100; 7084/6518 tok/s;   6062 sec
[2019-05-31 22:39:34,495 INFO] Step 12000/150000; acc:  63.77; ppl:  5.25; xent: 1.66; lr: 0.00100; 6861/6360 tok/s;   6328 sec
[2019-05-31 22:43:54,892 INFO] Step 12500/150000; acc:  63.79; ppl:  5.23; xent: 1.66; lr: 0.00100; 7006/6400 tok/s;   6589 sec
[2019-05-31 22:48:17,405 INFO] Step 13000/150000; acc:  64.16; ppl:  5.12; xent: 1.63; lr: 0.00100; 6958/6340 tok/s;   6851 sec
[2019-05-31 22:52:36,942 INFO] Step 13500/150000; acc:  64.17; ppl:  5.10; xent: 1.63; lr: 0.00100; 6998/6490 tok/s;   7111 sec
[2019-05-31 22:56:57,138 INFO] Step 14000/150000; acc:  64.44; ppl:  5.02; xent: 1.61; lr: 0.00100; 7028/6467 tok/s;   7371 sec
[2019-05-31 23:01:16,062 INFO] Step 14500/150000; acc:  64.71; ppl:  4.96; xent: 1.60; lr: 0.00100; 7006/6473 tok/s;   7630 sec
[2019-05-31 23:05:33,857 INFO] Step 15000/150000; acc:  64.74; ppl:  4.91; xent: 1.59; lr: 0.00100; 7105/6600 tok/s;   7887 sec
[2019-05-31 23:05:33,865 INFO] Loading dataset from ./data/onmt-vocab/fr-en.large.valid.0.pt, number of examples: 1500
[2019-05-31 23:05:49,665 INFO] Validation perplexity: 14.7918
[2019-05-31 23:05:49,665 INFO] Validation accuracy: 53.1963
[2019-05-31 23:05:49,666 INFO] Model is improving ppl: 18.1682 --> 14.7918.
[2019-05-31 23:05:49,666 INFO] Model is improving acc: 50.7126 --> 53.1963.
[2019-05-31 23:05:49,666 INFO] Saving checkpoint models/fr-en.large_step_15000.pt
[2019-05-31 23:10:15,521 INFO] Step 15500/150000; acc:  64.59; ppl:  4.96; xent: 1.60; lr: 0.00100; 6367/5850 tok/s;   8169 sec
[2019-05-31 23:12:26,001 INFO] Loading dataset from ./data/onmt-vocab/fr-en.large.train.2.pt, number of examples: 197758
[2019-05-31 23:14:45,064 INFO] Step 16000/150000; acc:  64.67; ppl:  4.92; xent: 1.59; lr: 0.00100; 6453/5995 tok/s;   8439 sec
[2019-05-31 23:19:15,482 INFO] Step 16500/150000; acc:  65.02; ppl:  4.83; xent: 1.58; lr: 0.00100; 6714/6176 tok/s;   8709 sec
[2019-05-31 23:23:33,040 INFO] Step 17000/150000; acc:  65.27; ppl:  4.77; xent: 1.56; lr: 0.00100; 6956/6376 tok/s;   8967 sec
[2019-05-31 23:27:06,171 INFO] Loading dataset from ./data/onmt-vocab/fr-en.large.train.0.pt, number of examples: 951312
[2019-05-31 23:28:08,512 INFO] Step 17500/150000; acc:  65.38; ppl:  4.74; xent: 1.56; lr: 0.00100; 6575/6086 tok/s;   9242 sec
[2019-05-31 23:32:29,217 INFO] Step 18000/150000; acc:  65.15; ppl:  4.77; xent: 1.56; lr: 0.00100; 7047/6475 tok/s;   9503 sec
[2019-05-31 23:36:51,663 INFO] Step 18500/150000; acc:  65.33; ppl:  4.73; xent: 1.55; lr: 0.00100; 6921/6424 tok/s;   9765 sec
[2019-05-31 23:41:06,496 INFO] Step 19000/150000; acc:  65.58; ppl:  4.66; xent: 1.54; lr: 0.00100; 7093/6550 tok/s;  10020 sec
[2019-05-31 23:45:42,114 INFO] Step 19500/150000; acc:  65.49; ppl:  4.67; xent: 1.54; lr: 0.00100; 6586/6075 tok/s;  10296 sec
[2019-05-31 23:50:22,628 INFO] Step 20000/150000; acc:  65.80; ppl:  4.59; xent: 1.52; lr: 0.00100; 6566/6027 tok/s;  10576 sec
[2019-05-31 23:50:22,637 INFO] Loading dataset from ./data/onmt-vocab/fr-en.large.valid.0.pt, number of examples: 1500
[2019-05-31 23:50:39,037 INFO] Validation perplexity: 13.1346
[2019-05-31 23:50:39,038 INFO] Validation accuracy: 55.071
[2019-05-31 23:50:39,038 INFO] Model is improving ppl: 14.7918 --> 13.1346.
[2019-05-31 23:50:39,038 INFO] Model is improving acc: 53.1963 --> 55.071.
[2019-05-31 23:50:39,038 INFO] Saving checkpoint models/fr-en.large_step_20000.pt
[2019-05-31 23:55:21,638 INFO] Step 20500/150000; acc:  65.71; ppl:  4.62; xent: 1.53; lr: 0.00100; 6085/5582 tok/s;  10875 sec
[2019-05-31 23:59:57,711 INFO] Step 21000/150000; acc:  65.99; ppl:  4.56; xent: 1.52; lr: 0.00100; 6600/6071 tok/s;  11151 sec
[2019-06-01 00:04:39,690 INFO] Step 21500/150000; acc:  66.15; ppl:  4.51; xent: 1.51; lr: 0.00100; 6488/6006 tok/s;  11433 sec
[2019-06-01 00:09:21,116 INFO] Step 22000/150000; acc:  65.79; ppl:  4.58; xent: 1.52; lr: 0.00100; 6497/5970 tok/s;  11715 sec
[2019-06-01 00:14:02,031 INFO] Step 22500/150000; acc:  66.07; ppl:  4.52; xent: 1.51; lr: 0.00100; 6493/5930 tok/s;  11996 sec
[2019-06-01 00:18:42,405 INFO] Step 23000/150000; acc:  66.16; ppl:  4.48; xent: 1.50; lr: 0.00100; 6479/6029 tok/s;  12276 sec
[2019-06-01 00:23:18,418 INFO] Step 23500/150000; acc:  66.47; ppl:  4.41; xent: 1.48; lr: 0.00100; 6587/6059 tok/s;  12552 sec
[2019-06-01 00:27:54,025 INFO] Step 24000/150000; acc:  66.40; ppl:  4.42; xent: 1.49; lr: 0.00100; 6633/6101 tok/s;  12828 sec
[2019-06-01 00:32:34,686 INFO] Step 24500/150000; acc:  66.43; ppl:  4.42; xent: 1.49; lr: 0.00100; 6506/5996 tok/s;  13108 sec
[2019-06-01 00:37:11,875 INFO] Step 25000/150000; acc:  66.63; ppl:  4.37; xent: 1.48; lr: 0.00100; 6492/5974 tok/s;  13385 sec
[2019-06-01 00:37:11,885 INFO] Loading dataset from ./data/onmt-vocab/fr-en.large.valid.0.pt, number of examples: 1500
[2019-06-01 00:37:27,788 INFO] Validation perplexity: 12.4757
[2019-06-01 00:37:27,789 INFO] Validation accuracy: 55.5411
[2019-06-01 00:37:27,789 INFO] Model is improving ppl: 13.1346 --> 12.4757.
[2019-06-01 00:37:27,789 INFO] Model is improving acc: 55.071 --> 55.5411.
[2019-06-01 00:37:27,789 INFO] Saving checkpoint models/fr-en.large_step_25000.pt
[2019-06-01 00:40:01,226 INFO] Loading dataset from ./data/onmt-vocab/fr-en.large.train.1.pt, number of examples: 951214
[2019-06-01 00:42:24,333 INFO] Step 25500/150000; acc:  66.23; ppl:  4.46; xent: 1.49; lr: 0.00100; 5626/5223 tok/s;  13698 sec
[2019-06-01 00:47:06,027 INFO] Step 26000/150000; acc:  66.62; ppl:  4.37; xent: 1.47; lr: 0.00100; 6494/5982 tok/s;  13980 sec
[2019-06-01 00:51:44,407 INFO] Step 26500/150000; acc:  66.76; ppl:  4.33; xent: 1.47; lr: 0.00100; 6565/6109 tok/s;  14258 sec
[2019-06-01 00:56:17,000 INFO] Step 27000/150000; acc:  66.94; ppl:  4.29; xent: 1.46; lr: 0.00100; 6649/6114 tok/s;  14531 sec
[2019-06-01 01:00:53,414 INFO] Step 27500/150000; acc:  66.73; ppl:  4.32; xent: 1.46; lr: 0.00100; 6574/6012 tok/s;  14807 sec
[2019-06-01 01:05:33,560 INFO] Step 28000/150000; acc:  66.66; ppl:  4.35; xent: 1.47; lr: 0.00100; 6525/5955 tok/s;  15087 sec
[2019-06-01 01:10:11,975 INFO] Step 28500/150000; acc:  66.92; ppl:  4.28; xent: 1.45; lr: 0.00100; 6553/6037 tok/s;  15366 sec
[2019-06-01 01:14:52,644 INFO] Step 29000/150000; acc:  66.94; ppl:  4.28; xent: 1.45; lr: 0.00100; 6543/6028 tok/s;  15646 sec
[2019-06-01 01:19:31,181 INFO] Step 29500/150000; acc:  66.86; ppl:  4.30; xent: 1.46; lr: 0.00100; 6523/6050 tok/s;  15925 sec
[2019-06-01 01:24:10,425 INFO] Step 30000/150000; acc:  67.08; ppl:  4.25; xent: 1.45; lr: 0.00050; 6570/5981 tok/s;  16204 sec
[2019-06-01 01:24:10,433 INFO] Loading dataset from ./data/onmt-vocab/fr-en.large.valid.0.pt, number of examples: 1500
[2019-06-01 01:24:26,924 INFO] Validation perplexity: 11.8665
[2019-06-01 01:24:26,924 INFO] Validation accuracy: 55.9521
[2019-06-01 01:24:26,925 INFO] Model is improving ppl: 12.4757 --> 11.8665.
[2019-06-01 01:24:26,925 INFO] Model is improving acc: 55.5411 --> 55.9521.
[2019-06-01 01:24:26,925 INFO] Saving checkpoint models/fr-en.large_step_30000.pt
[2019-06-01 01:29:02,192 INFO] Step 30500/150000; acc:  67.68; ppl:  4.10; xent: 1.41; lr: 0.00050; 6250/5706 tok/s;  16496 sec
[2019-06-01 01:33:21,575 INFO] Step 31000/150000; acc:  67.75; ppl:  4.08; xent: 1.41; lr: 0.00050; 7002/6497 tok/s;  16755 sec
[2019-06-01 01:37:41,087 INFO] Step 31500/150000; acc:  68.14; ppl:  4.00; xent: 1.39; lr: 0.00050; 7006/6485 tok/s;  17015 sec
[2019-06-01 01:42:02,458 INFO] Step 32000/150000; acc:  68.06; ppl:  4.01; xent: 1.39; lr: 0.00050; 6968/6441 tok/s;  17276 sec
[2019-06-01 01:46:23,577 INFO] Step 32500/150000; acc:  68.27; ppl:  3.95; xent: 1.37; lr: 0.00050; 7005/6480 tok/s;  17537 sec
[2019-06-01 01:50:54,854 INFO] Step 33000/150000; acc:  68.15; ppl:  3.98; xent: 1.38; lr: 0.00050; 6518/5983 tok/s;  17808 sec
[2019-06-01 01:52:05,068 INFO] Loading dataset from ./data/onmt-vocab/fr-en.large.train.2.pt, number of examples: 197758
[2019-06-01 01:55:29,097 INFO] Step 33500/150000; acc:  67.98; ppl:  4.00; xent: 1.39; lr: 0.00050; 6428/5984 tok/s;  18083 sec
[2019-06-01 01:59:53,621 INFO] Step 34000/150000; acc:  68.51; ppl:  3.90; xent: 1.36; lr: 0.00050; 6842/6272 tok/s;  18347 sec
[2019-06-01 02:04:12,475 INFO] Step 34500/150000; acc:  68.55; ppl:  3.89; xent: 1.36; lr: 0.00050; 6970/6362 tok/s;  18606 sec
[2019-06-01 02:06:45,497 INFO] Loading dataset from ./data/onmt-vocab/fr-en.large.train.0.pt, number of examples: 951312
[2019-06-01 02:08:47,465 INFO] Step 35000/150000; acc:  68.45; ppl:  3.91; xent: 1.36; lr: 0.00050; 6573/6121 tok/s;  18881 sec
[2019-06-01 02:08:47,472 INFO] Loading dataset from ./data/onmt-vocab/fr-en.large.valid.0.pt, number of examples: 1500
[2019-06-01 02:09:02,812 INFO] Validation perplexity: 10.5634
[2019-06-01 02:09:02,813 INFO] Validation accuracy: 57.9213
[2019-06-01 02:09:02,813 INFO] Model is improving ppl: 11.8665 --> 10.5634.
[2019-06-01 02:09:02,813 INFO] Model is improving acc: 55.9521 --> 57.9213.
[2019-06-01 02:09:02,813 INFO] Saving checkpoint models/fr-en.large_step_35000.pt
[2019-06-01 02:13:25,288 INFO] Step 35500/150000; acc:  68.57; ppl:  3.88; xent: 1.36; lr: 0.00050; 6629/6076 tok/s;  19159 sec
[2019-06-01 02:17:47,413 INFO] Step 36000/150000; acc:  68.58; ppl:  3.87; xent: 1.35; lr: 0.00050; 6928/6445 tok/s;  19421 sec
[2019-06-01 02:22:02,790 INFO] Step 36500/150000; acc:  68.62; ppl:  3.86; xent: 1.35; lr: 0.00050; 7077/6479 tok/s;  19676 sec
[2019-06-01 02:26:25,285 INFO] Step 37000/150000; acc:  68.58; ppl:  3.87; xent: 1.35; lr: 0.00050; 6929/6421 tok/s;  19939 sec
[2019-06-01 02:30:46,908 INFO] Step 37500/150000; acc:  68.79; ppl:  3.83; xent: 1.34; lr: 0.00050; 6998/6437 tok/s;  20201 sec
[2019-06-01 02:35:05,946 INFO] Step 38000/150000; acc:  68.78; ppl:  3.83; xent: 1.34; lr: 0.00050; 7036/6450 tok/s;  20460 sec
[2019-06-01 02:39:24,155 INFO] Step 38500/150000; acc:  68.90; ppl:  3.81; xent: 1.34; lr: 0.00050; 7068/6520 tok/s;  20718 sec
[2019-06-01 02:43:46,844 INFO] Step 39000/150000; acc:  68.80; ppl:  3.82; xent: 1.34; lr: 0.00050; 6950/6446 tok/s;  20980 sec
[2019-06-01 02:48:08,589 INFO] Step 39500/150000; acc:  68.85; ppl:  3.80; xent: 1.34; lr: 0.00050; 7024/6395 tok/s;  21242 sec
[2019-06-01 02:52:29,568 INFO] Step 40000/150000; acc:  68.83; ppl:  3.81; xent: 1.34; lr: 0.00025; 6963/6397 tok/s;  21503 sec
[2019-06-01 02:52:29,576 INFO] Loading dataset from ./data/onmt-vocab/fr-en.large.valid.0.pt, number of examples: 1500
[2019-06-01 02:52:45,324 INFO] Validation perplexity: 10.1504
[2019-06-01 02:52:45,325 INFO] Validation accuracy: 58.2466
[2019-06-01 02:52:45,325 INFO] Model is improving ppl: 10.5634 --> 10.1504.
[2019-06-01 02:52:45,325 INFO] Model is improving acc: 57.9213 --> 58.2466.
[2019-06-01 02:52:45,325 INFO] Saving checkpoint models/fr-en.large_step_40000.pt
[2019-06-01 02:57:09,005 INFO] Step 40500/150000; acc:  69.10; ppl:  3.74; xent: 1.32; lr: 0.00025; 6503/6024 tok/s;  21783 sec
[2019-06-01 03:01:24,536 INFO] Step 41000/150000; acc:  69.53; ppl:  3.67; xent: 1.30; lr: 0.00025; 7088/6569 tok/s;  22038 sec
[2019-06-01 03:05:45,249 INFO] Step 41500/150000; acc:  69.43; ppl:  3.68; xent: 1.30; lr: 0.00025; 7032/6472 tok/s;  22299 sec
[2019-06-01 03:10:04,888 INFO] Step 42000/150000; acc:  69.40; ppl:  3.69; xent: 1.31; lr: 0.00025; 7028/6494 tok/s;  22559 sec
[2019-06-01 03:14:27,299 INFO] Step 42500/150000; acc:  69.72; ppl:  3.62; xent: 1.29; lr: 0.00025; 6767/6188 tok/s;  22821 sec
[2019-06-01 03:15:54,536 INFO] Loading dataset from ./data/onmt-vocab/fr-en.large.train.1.pt, number of examples: 951214
[2019-06-01 03:19:07,407 INFO] Step 43000/150000; acc:  69.31; ppl:  3.70; xent: 1.31; lr: 0.00025; 6368/5943 tok/s;  23101 sec
[2019-06-01 03:23:30,801 INFO] Step 43500/150000; acc:  69.51; ppl:  3.66; xent: 1.30; lr: 0.00025; 6953/6379 tok/s;  23364 sec
[2019-06-01 03:27:47,415 INFO] Step 44000/150000; acc:  69.66; ppl:  3.63; xent: 1.29; lr: 0.00025; 7065/6624 tok/s;  23621 sec
[2019-06-01 03:32:03,932 INFO] Step 44500/150000; acc:  70.11; ppl:  3.54; xent: 1.26; lr: 0.00025; 7128/6499 tok/s;  23878 sec
[2019-06-01 03:36:28,251 INFO] Step 45000/150000; acc:  69.52; ppl:  3.64; xent: 1.29; lr: 0.00025; 6842/6279 tok/s;  24142 sec
[2019-06-01 03:36:28,259 INFO] Loading dataset from ./data/onmt-vocab/fr-en.large.valid.0.pt, number of examples: 1500
[2019-06-01 03:36:43,406 INFO] Validation perplexity: 9.85387
[2019-06-01 03:36:43,406 INFO] Validation accuracy: 58.6724
[2019-06-01 03:36:43,407 INFO] Model is improving ppl: 10.1504 --> 9.85387.
[2019-06-01 03:36:43,407 INFO] Model is improving acc: 58.2466 --> 58.6724.
[2019-06-01 03:36:43,407 INFO] Saving checkpoint models/fr-en.large_step_45000.pt
[2019-06-01 03:41:05,045 INFO] Step 45500/150000; acc:  69.89; ppl:  3.58; xent: 1.28; lr: 0.00025; 6631/5999 tok/s;  24419 sec
[2019-06-01 03:45:25,026 INFO] Step 46000/150000; acc:  69.91; ppl:  3.57; xent: 1.27; lr: 0.00025; 7018/6507 tok/s;  24679 sec
[2019-06-01 03:49:48,422 INFO] Step 46500/150000; acc:  69.94; ppl:  3.57; xent: 1.27; lr: 0.00025; 6943/6417 tok/s;  24942 sec
[2019-06-01 03:54:10,604 INFO] Step 47000/150000; acc:  69.99; ppl:  3.57; xent: 1.27; lr: 0.00025; 6947/6391 tok/s;  25204 sec
[2019-06-01 03:58:31,204 INFO] Step 47500/150000; acc:  70.11; ppl:  3.54; xent: 1.27; lr: 0.00025; 7047/6417 tok/s;  25465 sec
[2019-06-01 04:02:53,603 INFO] Step 48000/150000; acc:  69.65; ppl:  3.63; xent: 1.29; lr: 0.00025; 6933/6352 tok/s;  25727 sec
[2019-06-01 04:07:15,415 INFO] Step 48500/150000; acc:  69.72; ppl:  3.62; xent: 1.29; lr: 0.00025; 6944/6433 tok/s;  25989 sec
[2019-06-01 04:11:32,075 INFO] Step 49000/150000; acc:  70.09; ppl:  3.56; xent: 1.27; lr: 0.00025; 7073/6527 tok/s;  26246 sec
[2019-06-01 04:15:54,119 INFO] Step 49500/150000; acc:  69.72; ppl:  3.62; xent: 1.29; lr: 0.00025; 6967/6487 tok/s;  26508 sec
[2019-06-01 04:20:16,010 INFO] Step 50000/150000; acc:  69.92; ppl:  3.57; xent: 1.27; lr: 0.00013; 6979/6413 tok/s;  26770 sec
[2019-06-01 04:20:16,017 INFO] Loading dataset from ./data/onmt-vocab/fr-en.large.valid.0.pt, number of examples: 1500
[2019-06-01 04:20:32,900 INFO] Validation perplexity: 9.6658
[2019-06-01 04:20:32,901 INFO] Validation accuracy: 58.8794
[2019-06-01 04:20:32,901 INFO] Model is improving ppl: 9.85387 --> 9.6658.
[2019-06-01 04:20:32,901 INFO] Model is improving acc: 58.6724 --> 58.8794.
[2019-06-01 04:20:32,901 INFO] Saving checkpoint models/fr-en.large_step_50000.pt
[2019-06-01 04:25:07,052 INFO] Step 50500/150000; acc:  69.96; ppl:  3.56; xent: 1.27; lr: 0.00013; 5972/5518 tok/s;  27061 sec
[2019-06-01 04:25:14,653 INFO] Loading dataset from ./data/onmt-vocab/fr-en.large.train.2.pt, number of examples: 197758
[2019-06-01 04:29:39,177 INFO] Step 51000/150000; acc:  69.81; ppl:  3.59; xent: 1.28; lr: 0.00013; 6580/6098 tok/s;  27333 sec
[2019-06-01 04:34:00,614 INFO] Step 51500/150000; acc:  70.33; ppl:  3.50; xent: 1.25; lr: 0.00013; 6931/6332 tok/s;  27594 sec
[2019-06-01 04:38:18,904 INFO] Step 52000/150000; acc:  70.27; ppl:  3.51; xent: 1.25; lr: 0.00013; 6966/6393 tok/s;  27853 sec
[2019-06-01 04:39:53,046 INFO] Loading dataset from ./data/onmt-vocab/fr-en.large.train.0.pt, number of examples: 951312
[2019-06-01 04:42:53,894 INFO] Step 52500/150000; acc:  70.13; ppl:  3.53; xent: 1.26; lr: 0.00013; 6605/6158 tok/s;  28128 sec
[2019-06-01 04:47:15,946 INFO] Step 53000/150000; acc:  70.22; ppl:  3.51; xent: 1.25; lr: 0.00013; 7019/6423 tok/s;  28390 sec
[2019-06-01 04:51:33,546 INFO] Step 53500/150000; acc:  70.31; ppl:  3.49; xent: 1.25; lr: 0.00013; 7034/6585 tok/s;  28647 sec
[2019-06-01 04:55:54,763 INFO] Step 54000/150000; acc:  70.21; ppl:  3.50; xent: 1.25; lr: 0.00013; 6897/6306 tok/s;  28908 sec
[2019-06-01 05:00:17,692 INFO] Step 54500/150000; acc:  70.44; ppl:  3.47; xent: 1.24; lr: 0.00013; 6947/6442 tok/s;  29171 sec
[2019-06-01 05:04:37,135 INFO] Step 55000/150000; acc:  70.41; ppl:  3.46; xent: 1.24; lr: 0.00013; 7046/6422 tok/s;  29431 sec
[2019-06-01 05:04:37,143 INFO] Loading dataset from ./data/onmt-vocab/fr-en.large.valid.0.pt, number of examples: 1500
[2019-06-01 05:04:51,890 INFO] Validation perplexity: 9.5402
[2019-06-01 05:04:51,890 INFO] Validation accuracy: 58.9858
[2019-06-01 05:04:51,890 INFO] Model is improving ppl: 9.6658 --> 9.5402.
[2019-06-01 05:04:51,890 INFO] Model is improving acc: 58.8794 --> 58.9858.
[2019-06-01 05:04:51,890 INFO] Saving checkpoint models/fr-en.large_step_55000.pt
[2019-06-01 05:09:12,934 INFO] Step 55500/150000; acc:  70.49; ppl:  3.46; xent: 1.24; lr: 0.00013; 6611/6086 tok/s;  29707 sec
[2019-06-01 05:13:32,607 INFO] Step 56000/150000; acc:  70.54; ppl:  3.45; xent: 1.24; lr: 0.00013; 7039/6496 tok/s;  29966 sec
[2019-06-01 05:17:55,644 INFO] Step 56500/150000; acc:  70.60; ppl:  3.43; xent: 1.23; lr: 0.00013; 6960/6424 tok/s;  30229 sec
[2019-06-01 05:22:16,272 INFO] Step 57000/150000; acc:  70.65; ppl:  3.43; xent: 1.23; lr: 0.00013; 7039/6436 tok/s;  30490 sec
[2019-06-01 05:26:38,144 INFO] Step 57500/150000; acc:  70.40; ppl:  3.47; xent: 1.24; lr: 0.00013; 6926/6354 tok/s;  30752 sec
[2019-06-01 05:30:57,049 INFO] Step 58000/150000; acc:  70.25; ppl:  3.50; xent: 1.25; lr: 0.00013; 6985/6497 tok/s;  31011 sec
[2019-06-01 05:35:12,280 INFO] Step 58500/150000; acc:  70.73; ppl:  3.42; xent: 1.23; lr: 0.00013; 7138/6596 tok/s;  31266 sec
[2019-06-01 05:39:32,913 INFO] Step 59000/150000; acc:  70.44; ppl:  3.46; xent: 1.24; lr: 0.00013; 7028/6493 tok/s;  31527 sec
[2019-06-01 05:43:53,270 INFO] Step 59500/150000; acc:  70.37; ppl:  3.48; xent: 1.25; lr: 0.00013; 7024/6422 tok/s;  31787 sec
[2019-06-01 05:48:22,343 INFO] Step 60000/150000; acc:  70.77; ppl:  3.41; xent: 1.23; lr: 0.00006; 6492/5979 tok/s;  32056 sec
[2019-06-01 05:48:22,354 INFO] Loading dataset from ./data/onmt-vocab/fr-en.large.valid.0.pt, number of examples: 1500
[2019-06-01 05:48:38,808 INFO] Validation perplexity: 9.43427
[2019-06-01 05:48:38,808 INFO] Validation accuracy: 59.0272
[2019-06-01 05:48:38,808 INFO] Model is improving ppl: 9.5402 --> 9.43427.
[2019-06-01 05:48:38,808 INFO] Model is improving acc: 58.9858 --> 59.0272.
[2019-06-01 05:48:38,808 INFO] Saving checkpoint models/fr-en.large_step_60000.pt
[2019-06-01 05:49:04,842 INFO] Loading dataset from ./data/onmt-vocab/fr-en.large.train.1.pt, number of examples: 951214
[2019-06-01 05:53:16,604 INFO] Step 60500/150000; acc:  70.21; ppl:  3.50; xent: 1.25; lr: 0.00006; 6164/5727 tok/s;  32350 sec
[2019-06-01 05:57:41,028 INFO] Step 61000/150000; acc:  70.52; ppl:  3.45; xent: 1.24; lr: 0.00006; 6909/6374 tok/s;  32615 sec
[2019-06-01 06:01:58,028 INFO] Step 61500/150000; acc:  70.63; ppl:  3.43; xent: 1.23; lr: 0.00006; 7052/6591 tok/s;  32872 sec
[2019-06-01 06:06:13,153 INFO] Step 62000/150000; acc:  71.08; ppl:  3.35; xent: 1.21; lr: 0.00006; 7194/6545 tok/s;  33127 sec
[2019-06-01 06:10:33,582 INFO] Step 62500/150000; acc:  70.53; ppl:  3.45; xent: 1.24; lr: 0.00006; 6942/6348 tok/s;  33387 sec
[2019-06-01 06:15:04,450 INFO] Step 63000/150000; acc:  70.85; ppl:  3.40; xent: 1.22; lr: 0.00006; 6753/6157 tok/s;  33658 sec
[2019-06-01 06:19:25,628 INFO] Step 63500/150000; acc:  70.76; ppl:  3.39; xent: 1.22; lr: 0.00006; 6995/6483 tok/s;  33919 sec
[2019-06-01 06:23:47,821 INFO] Step 64000/150000; acc:  70.84; ppl:  3.39; xent: 1.22; lr: 0.00006; 6953/6456 tok/s;  34181 sec
[2019-06-01 06:28:09,427 INFO] Step 64500/150000; acc:  70.98; ppl:  3.37; xent: 1.22; lr: 0.00006; 6980/6392 tok/s;  34443 sec
[2019-06-01 06:32:29,279 INFO] Step 65000/150000; acc:  70.98; ppl:  3.37; xent: 1.21; lr: 0.00006; 7048/6408 tok/s;  34703 sec
[2019-06-01 06:32:29,286 INFO] Loading dataset from ./data/onmt-vocab/fr-en.large.valid.0.pt, number of examples: 1500
[2019-06-01 06:32:44,029 INFO] Validation perplexity: 9.33896
[2019-06-01 06:32:44,030 INFO] Validation accuracy: 59.3554
[2019-06-01 06:32:44,030 INFO] Model is improving ppl: 9.43427 --> 9.33896.
[2019-06-01 06:32:44,030 INFO] Model is improving acc: 59.0272 --> 59.3554.
[2019-06-01 06:32:44,030 INFO] Saving checkpoint models/fr-en.large_step_65000.pt
[2019-06-01 06:37:06,711 INFO] Step 65500/150000; acc:  70.71; ppl:  3.41; xent: 1.23; lr: 0.00006; 6570/6030 tok/s;  34980 sec
[2019-06-01 06:41:25,740 INFO] Step 66000/150000; acc:  70.64; ppl:  3.42; xent: 1.23; lr: 0.00006; 7029/6526 tok/s;  35239 sec
[2019-06-01 06:45:47,230 INFO] Step 66500/150000; acc:  70.95; ppl:  3.38; xent: 1.22; lr: 0.00006; 6934/6396 tok/s;  35501 sec
[2019-06-01 06:50:05,735 INFO] Step 67000/150000; acc:  70.87; ppl:  3.38; xent: 1.22; lr: 0.00006; 7070/6602 tok/s;  35759 sec
[2019-06-01 06:54:28,922 INFO] Step 67500/150000; acc:  70.77; ppl:  3.41; xent: 1.23; lr: 0.00006; 6957/6353 tok/s;  36023 sec
[2019-06-01 06:58:08,142 INFO] Loading dataset from ./data/onmt-vocab/fr-en.large.train.2.pt, number of examples: 197758
[2019-06-01 06:59:06,106 INFO] Step 68000/150000; acc:  70.58; ppl:  3.44; xent: 1.23; lr: 0.00006; 6233/5769 tok/s;  36300 sec
[2019-06-01 07:03:33,346 INFO] Step 68500/150000; acc:  70.53; ppl:  3.44; xent: 1.24; lr: 0.00006; 6726/6196 tok/s;  36567 sec
[2019-06-01 07:07:55,783 INFO] Step 69000/150000; acc:  70.82; ppl:  3.40; xent: 1.22; lr: 0.00006; 6864/6298 tok/s;  36829 sec
[2019-06-01 07:12:18,199 INFO] Step 69500/150000; acc:  70.89; ppl:  3.39; xent: 1.22; lr: 0.00006; 6876/6347 tok/s;  37092 sec
[2019-06-01 07:12:53,242 INFO] Loading dataset from ./data/onmt-vocab/fr-en.large.train.0.pt, number of examples: 951312
[2019-06-01 07:16:53,367 INFO] Step 70000/150000; acc:  70.64; ppl:  3.42; xent: 1.23; lr: 0.00003; 6631/6133 tok/s;  37367 sec
[2019-06-01 07:16:53,374 INFO] Loading dataset from ./data/onmt-vocab/fr-en.large.valid.0.pt, number of examples: 1500
[2019-06-01 07:17:08,071 INFO] Validation perplexity: 9.32181
[2019-06-01 07:17:08,071 INFO] Validation accuracy: 59.3377
[2019-06-01 07:17:08,072 INFO] Stalled patience: 4/5
[2019-06-01 07:17:08,072 INFO] Saving checkpoint models/fr-en.large_step_70000.pt
[2019-06-01 07:21:31,717 INFO] Step 70500/150000; acc:  70.75; ppl:  3.40; xent: 1.22; lr: 0.00003; 6593/6077 tok/s;  37645 sec
[2019-06-01 07:25:48,708 INFO] Step 71000/150000; acc:  70.82; ppl:  3.39; xent: 1.22; lr: 0.00003; 7022/6563 tok/s;  37902 sec
[2019-06-01 07:30:06,119 INFO] Step 71500/150000; acc:  70.84; ppl:  3.39; xent: 1.22; lr: 0.00003; 7035/6436 tok/s;  38160 sec
[2019-06-01 07:34:26,954 INFO] Step 72000/150000; acc:  70.97; ppl:  3.37; xent: 1.21; lr: 0.00003; 7013/6462 tok/s;  38421 sec
[2019-06-01 07:38:49,314 INFO] Step 72500/150000; acc:  70.85; ppl:  3.38; xent: 1.22; lr: 0.00003; 6956/6363 tok/s;  38683 sec
[2019-06-01 07:43:07,350 INFO] Step 73000/150000; acc:  71.10; ppl:  3.34; xent: 1.21; lr: 0.00003; 7080/6531 tok/s;  38941 sec
[2019-06-01 07:47:27,492 INFO] Step 73500/150000; acc:  71.15; ppl:  3.34; xent: 1.20; lr: 0.00003; 7020/6486 tok/s;  39201 sec
[2019-06-01 07:51:48,187 INFO] Step 74000/150000; acc:  71.11; ppl:  3.34; xent: 1.20; lr: 0.00003; 7010/6454 tok/s;  39462 sec
[2019-06-01 07:56:09,570 INFO] Step 74500/150000; acc:  71.08; ppl:  3.34; xent: 1.21; lr: 0.00003; 6994/6399 tok/s;  39723 sec
[2019-06-01 08:00:29,892 INFO] Step 75000/150000; acc:  70.98; ppl:  3.36; xent: 1.21; lr: 0.00003; 6981/6415 tok/s;  39984 sec
[2019-06-01 08:00:29,900 INFO] Loading dataset from ./data/onmt-vocab/fr-en.large.valid.0.pt, number of examples: 1500
[2019-06-01 08:00:45,753 INFO] Validation perplexity: 9.31228
[2019-06-01 08:00:45,754 INFO] Validation accuracy: 59.3318
[2019-06-01 08:00:45,754 INFO] Stalled patience: 3/5
[2019-06-01 08:00:45,754 INFO] Saving checkpoint models/fr-en.large_step_75000.pt
[2019-06-01 08:05:10,751 INFO] Step 75500/150000; acc:  70.79; ppl:  3.39; xent: 1.22; lr: 0.00003; 6466/5983 tok/s;  40264 sec
[2019-06-01 08:09:31,919 INFO] Step 76000/150000; acc:  71.00; ppl:  3.36; xent: 1.21; lr: 0.00003; 6979/6453 tok/s;  40526 sec
[2019-06-01 08:13:51,305 INFO] Step 76500/150000; acc:  71.20; ppl:  3.33; xent: 1.20; lr: 0.00003; 7055/6517 tok/s;  40785 sec
[2019-06-01 08:18:11,698 INFO] Step 77000/150000; acc:  70.88; ppl:  3.38; xent: 1.22; lr: 0.00003; 7016/6408 tok/s;  41045 sec
[2019-06-01 08:22:02,814 INFO] Loading dataset from ./data/onmt-vocab/fr-en.large.train.1.pt, number of examples: 951214
[2019-06-01 08:22:53,679 INFO] Step 77500/150000; acc:  71.20; ppl:  3.33; xent: 1.20; lr: 0.00003; 6179/5725 tok/s;  41327 sec
[2019-06-01 08:27:15,437 INFO] Step 78000/150000; acc:  70.63; ppl:  3.42; xent: 1.23; lr: 0.00003; 6955/6466 tok/s;  41589 sec
[2019-06-01 08:31:36,095 INFO] Step 78500/150000; acc:  70.91; ppl:  3.38; xent: 1.22; lr: 0.00003; 6983/6480 tok/s;  41850 sec
[2019-06-01 08:35:52,196 INFO] Step 79000/150000; acc:  70.96; ppl:  3.37; xent: 1.21; lr: 0.00003; 7084/6555 tok/s;  42106 sec
[2019-06-01 08:40:09,570 INFO] Step 79500/150000; acc:  71.17; ppl:  3.33; xent: 1.20; lr: 0.00003; 7104/6461 tok/s;  42363 sec
[2019-06-01 08:44:28,801 INFO] Step 80000/150000; acc:  71.00; ppl:  3.35; xent: 1.21; lr: 0.00002; 7023/6407 tok/s;  42622 sec
[2019-06-01 08:44:28,809 INFO] Loading dataset from ./data/onmt-vocab/fr-en.large.valid.0.pt, number of examples: 1500
[2019-06-01 08:44:43,659 INFO] Validation perplexity: 9.29685
[2019-06-01 08:44:43,659 INFO] Validation accuracy: 59.3465
[2019-06-01 08:44:43,659 INFO] Stalled patience: 2/5
[2019-06-01 08:44:43,659 INFO] Saving checkpoint models/fr-en.large_step_80000.pt
[2019-06-01 08:49:07,322 INFO] Step 80500/150000; acc:  71.03; ppl:  3.35; xent: 1.21; lr: 0.00002; 6571/6041 tok/s;  42901 sec
[2019-06-01 08:53:24,994 INFO] Step 81000/150000; acc:  70.98; ppl:  3.35; xent: 1.21; lr: 0.00002; 7089/6523 tok/s;  43159 sec
[2019-06-01 08:57:48,346 INFO] Step 81500/150000; acc:  71.28; ppl:  3.31; xent: 1.20; lr: 0.00002; 6922/6428 tok/s;  43422 sec
[2019-06-01 09:02:08,437 INFO] Step 82000/150000; acc:  71.24; ppl:  3.32; xent: 1.20; lr: 0.00002; 7023/6408 tok/s;  43682 sec
[2019-06-01 09:06:30,049 INFO] Step 82500/150000; acc:  71.06; ppl:  3.35; xent: 1.21; lr: 0.00002; 6976/6355 tok/s;  43944 sec
[2019-06-01 09:10:49,796 INFO] Step 83000/150000; acc:  71.08; ppl:  3.34; xent: 1.21; lr: 0.00002; 7026/6491 tok/s;  44203 sec
[2019-06-01 09:15:09,911 INFO] Step 83500/150000; acc:  70.93; ppl:  3.37; xent: 1.22; lr: 0.00002; 6998/6481 tok/s;  44464 sec
[2019-06-01 09:19:27,293 INFO] Step 84000/150000; acc:  71.29; ppl:  3.32; xent: 1.20; lr: 0.00002; 7061/6520 tok/s;  44721 sec
[2019-06-01 09:23:43,342 INFO] Step 84500/150000; acc:  71.10; ppl:  3.33; xent: 1.20; lr: 0.00002; 7144/6645 tok/s;  44977 sec
[2019-06-01 09:28:06,988 INFO] Step 85000/150000; acc:  70.94; ppl:  3.37; xent: 1.22; lr: 0.00002; 6845/6288 tok/s;  45241 sec
[2019-06-01 09:28:06,999 INFO] Loading dataset from ./data/onmt-vocab/fr-en.large.valid.0.pt, number of examples: 1500
[2019-06-01 09:28:22,821 INFO] Validation perplexity: 9.29753
[2019-06-01 09:28:22,821 INFO] Validation accuracy: 59.2756
[2019-06-01 09:28:22,821 INFO] Stalled patience: 1/5
[2019-06-01 09:28:22,822 INFO] Saving checkpoint models/fr-en.large_step_85000.pt
[2019-06-01 09:30:58,178 INFO] Loading dataset from ./data/onmt-vocab/fr-en.large.train.2.pt, number of examples: 197758
[2019-06-01 09:32:53,827 INFO] Step 85500/150000; acc:  70.86; ppl:  3.38; xent: 1.22; lr: 0.00002; 6047/5580 tok/s;  45527 sec
[2019-06-01 09:37:19,144 INFO] Step 86000/150000; acc:  70.84; ppl:  3.38; xent: 1.22; lr: 0.00002; 6821/6304 tok/s;  45793 sec
[2019-06-01 09:41:37,711 INFO] Step 86500/150000; acc:  71.13; ppl:  3.34; xent: 1.20; lr: 0.00002; 6940/6371 tok/s;  46051 sec
[2019-06-01 09:45:32,380 INFO] Loading dataset from ./data/onmt-vocab/fr-en.large.train.0.pt, number of examples: 951312
[2019-06-01 09:46:11,498 INFO] Step 87000/150000; acc:  71.22; ppl:  3.33; xent: 1.20; lr: 0.00002; 6607/6084 tok/s;  46325 sec
[2019-06-01 09:50:32,408 INFO] Step 87500/150000; acc:  70.96; ppl:  3.37; xent: 1.21; lr: 0.00002; 7031/6496 tok/s;  46586 sec
[2019-06-01 09:54:52,821 INFO] Step 88000/150000; acc:  70.88; ppl:  3.38; xent: 1.22; lr: 0.00002; 6972/6464 tok/s;  46846 sec
[2019-06-01 09:59:08,025 INFO] Step 88500/150000; acc:  70.99; ppl:  3.36; xent: 1.21; lr: 0.00002; 7105/6566 tok/s;  47102 sec
[2019-06-01 10:03:29,126 INFO] Step 89000/150000; acc:  70.89; ppl:  3.37; xent: 1.22; lr: 0.00002; 6940/6392 tok/s;  47363 sec
[2019-06-01 10:07:50,619 INFO] Step 89500/150000; acc:  71.23; ppl:  3.31; xent: 1.20; lr: 0.00002; 7035/6455 tok/s;  47624 sec
[2019-06-01 10:12:12,558 INFO] Step 90000/150000; acc:  71.06; ppl:  3.35; xent: 1.21; lr: 0.00001; 6951/6367 tok/s;  47886 sec
[2019-06-01 10:12:12,566 INFO] Loading dataset from ./data/onmt-vocab/fr-en.large.valid.0.pt, number of examples: 1500
[2019-06-01 10:12:27,224 INFO] Validation perplexity: 9.30431
[2019-06-01 10:12:27,224 INFO] Validation accuracy: 59.2844
[2019-06-01 10:12:27,224 INFO] Stalled patience: 0/5
[2019-06-01 10:12:27,225 INFO] Training finished after stalled validations. Early Stop!
[2019-06-01 10:12:27,225 INFO] Best model found at step 65000
[2019-06-01 10:12:27,275 INFO] Saving checkpoint models/fr-en.large_step_90000.pt
